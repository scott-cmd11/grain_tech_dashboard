{
  "generated_at": "2026-01-14T16:10:51.929072",
  "total_items": 298,
  "category_counts": {
    "vertical_grain": 1,
    "deep_dive": 297,
    "headline": 0,
    "tools": 0,
    "bright_spot": 0
  },
  "articles": [
    {
      "title": "Need automated, accurate grain grading in minutes?",
      "link": "https://groundtruth.ag#benchtopmvnirs",
      "summary": "",
      "published": "2026-01-14T16:10:46.838741",
      "source": "Ground Truth Ag",
      "category": "vertical_grain"
    },
    {
      "title": "Bridging the Trust Gap: Clinician-Validated Hybrid Explainable AI for Maternal Health Risk Assessment in Bangladesh",
      "link": "https://arxiv.org/abs/2601.07866",
      "summary": "arXiv:2601.07866v1 Announce Type: new \nAbstract: While machine learning shows promise for maternal health risk prediction, clinical adoption in resource-constrained settings faces a critical barrier: lack of explainability and trust. This study presents a hybrid explainable AI (XAI) framework combining ante-hoc fuzzy logic with post-hoc SHAP explanations, validated through systematic clinician feedback. We developed a fuzzy-XGBoost model on 1,014 maternal health records, achieving 88.67% accurac",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Executable Ontologies in Game Development: From Algorithmic Control to Semantic World Modeling",
      "link": "https://arxiv.org/abs/2601.07964",
      "summary": "arXiv:2601.07964v1 Announce Type: new \nAbstract: This paper examines the application of Executable Ontologies (EO), implemented through the boldsea framework, to game development. We argue that EO represents a paradigm shift: a transition from algorithmic behavior programming to semantic world modeling, where agent behavior emerges naturally from declarative domain rules rather than being explicitly coded. Using a survival game scenario (Winter Feast), we demonstrate how EO achieves prioritybase",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "When Models Know When They Do Not Know: Calibration, Cascading, and Cleaning",
      "link": "https://arxiv.org/abs/2601.07965",
      "summary": "arXiv:2601.07965v1 Announce Type: new \nAbstract: When a model knows when it does not know, many possibilities emerge. The first question is how to enable a model to recognize that it does not know. A promising approach is to use confidence, computed from the model's internal signals, to reflect its ignorance. Prior work in specific domains has shown that calibration can provide reliable confidence estimates. In this work, we propose a simple, effective, and universal training-free method that ap",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety",
      "link": "https://arxiv.org/abs/2601.08000",
      "summary": "arXiv:2601.08000v1 Announce Type: new \nAbstract: Ensuring that Large Language Models (LLMs) adhere to safety principles without refusing benign requests remains a significant challenge. While OpenAI introduces deliberative alignment (DA) to enhance the safety of its o-series models through reasoning over detailed ``code-like'' safety rules, the effectiveness of this approach in open-source LLMs, which typically lack advanced reasoning capabilities, is understudied. In this work, we systematicall",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Internal Deployment Gaps in AI Regulation",
      "link": "https://arxiv.org/abs/2601.08005",
      "summary": "arXiv:2601.08005v1 Announce Type: new \nAbstract: Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations, such as for automating R\\&amp;D, accelerating critical business processes, and handling sensitive proprietary data. This paper examines how frontier AI regulations in the Uni",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms",
      "link": "https://arxiv.org/abs/2601.08049",
      "summary": "arXiv:2601.08049v1 Announce Type: new \nAbstract: The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students' emotional and cognitive engagement during lectures. This limits instructors' ability to identify disengagement and adapt teaching strategies in real time. This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms",
      "link": "https://arxiv.org/abs/2601.08052",
      "summary": "arXiv:2601.08052v1 Announce Type: new \nAbstract: Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean energy. However, the intermittent nature of renewables poses challenges in balancing supply and demand in real time. Intelligent load scheduling is the",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems",
      "link": "https://arxiv.org/abs/2601.08065",
      "summary": "arXiv:2601.08065v1 Announce Type: new \nAbstract: Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems (dynamical systems controlled by neural networks). This dominance stems from the limited scalability of existing backward reachability methods. In this work, we introduce new algorithms that compute both over- and under-approximations of backward reachable sets for such systems. We further integrate these backward algorithms wi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Semantic Gravity Wells: Why Negative Constraints Backfire",
      "link": "https://arxiv.org/abs/2601.08070",
      "summary": "arXiv:2601.08070v1 Announce Type: new \nAbstract: Negative constraints (instructions of the form \"do not use word X\") represent a fundamental test of instruction-following capability in large language models. Despite their apparent simplicity, these constraints fail with striking regularity, and the conditions governing failure have remained poorly understood. This paper presents the first comprehensive mechanistic investigation of negative instruction failure. We introduce semantic pressure, a q",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MemoBrain: Executive Memory as an Agentic Brain for Reasoning",
      "link": "https://arxiv.org/abs/2601.08079",
      "summary": "arXiv:2601.08079v1 Announce Type: new \nAbstract: Complex reasoning in tool-augmented agent frameworks is inherently long-horizon, causing reasoning traces and transient tool artifacts to accumulate and strain the bounded working context of large language models. Without explicit memory mechanisms, such accumulation disrupts logical continuity and undermines task alignment. This positions memory not as an auxiliary efficiency concern, but as a core component for sustaining coherent, goal-directed",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MirrorBench: An Extensible Framework to Evaluate User-Proxy Agents for Human-Likeness",
      "link": "https://arxiv.org/abs/2601.08118",
      "summary": "arXiv:2601.08118v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used as human simulators, both for evaluating conversational systems and for generating fine-tuning data. However, naive \"act-as-a-user\" prompting often yields verbose, unrealistic utterances, underscoring the need for principled evaluation of so-called user proxy agents. We present MIRRORBENCH, a reproducible, extensible benchmarking framework that evaluates user proxies solely on their ability to pro",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "How vehicles change lanes after encountering crashes: Empirical analysis and modeling",
      "link": "https://arxiv.org/abs/2601.08125",
      "summary": "arXiv:2601.08125v1 Announce Type: new \nAbstract: When a traffic crash occurs, following vehicles need to change lanes to bypass the obstruction. We define these maneuvers as post crash lane changes. In such scenarios, vehicles in the target lane may refuse to yield even after the lane change has already begun, increasing the complexity and crash risk of post crash LCs. However, the behavioral characteristics and motion patterns of post crash LCs remain unknown. To address this gap, we construct ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Embedded AI Companion System on Edge Devices",
      "link": "https://arxiv.org/abs/2601.08128",
      "summary": "arXiv:2601.08128v1 Announce Type: new \nAbstract: Computational resource constraints on edge devices make it difficult to develop a fully embedded AI companion system with a satisfactory user experience. AI companion and memory systems detailed in existing literature cannot be directly used in such an environment due to lack of compute resources and latency concerns. In this paper, we propose a memory paradigm that alternates between active and inactive phases: during phases of user activity, the",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions",
      "link": "https://arxiv.org/abs/2601.08156",
      "summary": "arXiv:2601.08156v1 Announce Type: new \nAbstract: This paper introduces Project Synapse, a novel agentic framework designed for the autonomous resolution of last-mile delivery disruptions. Synapse employs a hierarchical multi-agent architecture in which a central Resolution Supervisor agent performs strategic task decomposition and delegates subtasks to specialized worker agents responsible for tactical execution. The system is orchestrated using LangGraph to manage complex and cyclical workflows",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms",
      "link": "https://arxiv.org/abs/2601.08166",
      "summary": "arXiv:2601.08166v1 Announce Type: new \nAbstract: Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. We propose a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Agent's First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios",
      "link": "https://arxiv.org/abs/2601.08173",
      "summary": "arXiv:2601.08173v1 Announce Type: new \nAbstract: The rapid evolution of Multi-modal Large Language Models (MLLMs) has advanced workflow automation; however, existing research mainly targets performance upper bounds in static environments, overlooking robustness for stochastic real-world deployment. We identify three key challenges: dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. To bridge this gap, we introduce \\method{}, a dynamic evaluati",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Improving LLM Reasoning with Homophily-aware Structural and Semantic Text-Attributed Graph Compression",
      "link": "https://arxiv.org/abs/2601.08187",
      "summary": "arXiv:2601.08187v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated promising capabilities in Text-Attributed Graph (TAG) understanding. Recent studies typically focus on verbalizing the graph structures via handcrafted prompts, feeding the target node and its neighborhood context into LLMs. However, constrained by the context window, existing methods mainly resort to random sampling, often implemented via dropping node/edge randomly, which inevitably introduces noise",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Adapting Rules of Official International Mahjong for Online Players",
      "link": "https://arxiv.org/abs/2601.08211",
      "summary": "arXiv:2601.08211v1 Announce Type: new \nAbstract: As one of the worldwide spread traditional game, Official International Mahjong can be played and promoted online through remote devices instead of requiring face-to-face interaction. However, online players have fragmented playtime and unfixed combination of opponents in contrary to offline players who have fixed opponents for multiple rounds of play. Therefore, the rules designed for offline players need to be modified to ensure the fairness of ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3",
      "link": "https://arxiv.org/abs/2601.08224",
      "summary": "arXiv:2601.08224v1 Announce Type: new \nAbstract: General intelligence must reorganize experience into internal structures that enable prediction and action under finite resources. Existing systems implicitly presuppose fixed primitive units -- tokens, subwords, pixels, or predefined sensor channels -- thereby bypassing the question of how representational units themselves emerge and stabilize. This paper proposes SANC(E3), an axiomatic framework in which representational units are not given a pr",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity Evaluation of Language Model Agents",
      "link": "https://arxiv.org/abs/2601.08235",
      "summary": "arXiv:2601.08235v1 Announce Type: new \nAbstract: As language-model agents evolve from passive chatbots into proactive assistants that handle personal data, evaluating their adherence to social norms becomes increasingly critical, often through the lens of Contextual Integrity (CI). However, existing CI benchmarks are largely text-centric and primarily emphasize negative refusal scenarios, overlooking multimodal privacy risks and the fundamental trade-off between privacy and utility. In this pape",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination",
      "link": "https://arxiv.org/abs/2601.08237",
      "summary": "arXiv:2601.08237v1 Announce Type: new \nAbstract: Reward engineering, the manual specification of reward functions to induce desired agent behavior, remains a fundamental challenge in multi-agent reinforcement learning. This difficulty is amplified by credit assignment ambiguity, environmental non-stationarity, and the combinatorial growth of interaction complexity. We argue that recent advances in large language models (LLMs) point toward a shift from hand-crafted numerical rewards to language-b",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Large Artificial Intelligence Model Guided Deep Reinforcement Learning for Resource Allocation in Non Terrestrial Networks",
      "link": "https://arxiv.org/abs/2601.08254",
      "summary": "arXiv:2601.08254v1 Announce Type: new \nAbstract: Large AI Model (LAM) have been proposed to applications of Non-Terrestrial Networks (NTN), that offer better performance with its great generalization and reduced task specific trainings. In this paper, we propose a Deep Reinforcement Learning (DRL) agent that is guided by a Large Language Model (LLM). The LLM operates as a high level coordinator that generates textual guidance that shape the reward of the DRL agent during training. The results sh",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "T3: Benchmarking Sycophancy and Skepticism in Causal Judgment",
      "link": "https://arxiv.org/abs/2601.08258",
      "summary": "arXiv:2601.08258v1 Announce Type: new \nAbstract: We introduce T3 (Testing Trustworthy Thinking), a diagnostic benchmark designed to rigorously evaluate LLM causal judgment across Pearl's Ladder of Causality. Comprising 454 expert-curated vignettes, T3 prioritizes high-resolution failure analysis, decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. By applying T3 to frontier models, we diagnose two distinct pathologies: a \"Skepticis",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VGG Induced Deep Hand Sign Language Detection",
      "link": "https://arxiv.org/abs/2601.08262",
      "summary": "arXiv:2601.08262v1 Announce Type: new \nAbstract: Hand gesture recognition is an important aspect of human-computer interaction. It forms the basis of sign language for the visually impaired people. This work proposes a novel hand gesture recognizing system for the differently-abled persons. The model uses a convolutional neural network, known as VGG-16 net, for building a trained model on a widely used image dataset by employing Python and Keras libraries. Furthermore, the result is validated by",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces",
      "link": "https://arxiv.org/abs/2601.08271",
      "summary": "arXiv:2601.08271v1 Announce Type: new \nAbstract: Tool-augmented LLM systems expose a control regime that learning theory has largely ignored: sequential decision-making with a massive discrete action universe (tools, APIs, documents) in which only a small, unknown subset is relevant for any fixed task distribution. We formalize this setting as Sparse Agentic Control (SAC), where policies admit block-sparse representations over M >> 1 actions and rewards depend on sparse main effects and (optiona",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ToolACE-MCP: Generalizing History-Aware Routing from MCP Tools to the Agent Web",
      "link": "https://arxiv.org/abs/2601.08276",
      "summary": "arXiv:2601.08276v1 Announce Type: new \nAbstract: With the rise of the Agent Web and Model Context Protocol (MCP), the agent ecosystem is evolving into an open collaborative network, exponentially increasing accessible tools. However, current architectures face severe scalability and generality bottlenecks. To address this, we propose ToolACE-MCP, a pipeline for training history-aware routers to empower precise navigation in large-scale ecosystems. By leveraging a dependency-rich candidate Graph ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Greedy Is Enough: Sparse Action Discovery in Agentic LLMs",
      "link": "https://arxiv.org/abs/2601.08280",
      "summary": "arXiv:2601.08280v1 Announce Type: new \nAbstract: Modern agentic systems operate in environments with extremely large action spaces, such as tool-augmented language models with thousands of available APIs or retrieval operations. Despite this scale, empirical evidence suggests that only a small subset of actions meaningfully influences performance in a given deployment. Motivated by this observation, we study a contextual linear reward model in which action relevance is governed by a structured s",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System",
      "link": "https://arxiv.org/abs/2601.08288",
      "summary": "arXiv:2601.08288v1 Announce Type: new \nAbstract: Chinese stand-up comedy generation goes beyond plain text generation, requiring culturally grounded humor, precise timing, stage-performance cues, and implicit multi-step reasoning. Moreover, commonly used Chinese humor datasets are often better suited for humor understanding and evaluation than for long-form stand-up generation, making direct supervision misaligned with the target task. To address these challenges, we present OpenMic, an end-to-e",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation",
      "link": "https://arxiv.org/abs/2601.08323",
      "summary": "arXiv:2601.08323v1 Announce Type: new \nAbstract: Equipping agents with memory is essential for solving real-world long-horizon problems. However, most existing agent memory mechanisms rely on static and hand-crafted workflows. This limits the performance and generalization ability of these memory designs, which highlights the need for a more flexible, learning-based memory framework. In this paper, we propose AtomMem, which reframes memory management as a dynamic decision-making problem. We deco",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant",
      "link": "https://arxiv.org/abs/2601.08333",
      "summary": "arXiv:2601.08333v1 Announce Type: new \nAbstract: LLM-based agent architectures systematically conflate information transport mechanisms with epistemic justification mechanisms. We formalize this class of architectural failures as semantic laundering: a pattern where propositions with absent or weak warrant are accepted by the system as admissible by crossing architecturally trusted interfaces. We show that semantic laundering constitutes an architectural realization of the Gettier problem: propo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Thematic Working Group 5 -- Artificial Intelligence (AI) literacy for teaching and learning: design and implementation",
      "link": "https://arxiv.org/abs/2601.08380",
      "summary": "arXiv:2601.08380v1 Announce Type: new \nAbstract: TWG 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. Explorations covered curriculum design, professional development programs, practical classroom applications, and policy guidelines aiming to empower educators to confidently utilize AI tools and foster a deeper understanding of AI co",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Qualitative Model to Reason about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT)",
      "link": "https://arxiv.org/abs/2601.08382",
      "summary": "arXiv:2601.08382v1 Announce Type: new \nAbstract: This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change (CNGRLO) of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations.",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models",
      "link": "https://arxiv.org/abs/2601.08383",
      "summary": "arXiv:2601.08383v1 Announce Type: new \nAbstract: Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. Yet how MoE architectures shape knowledge acquisition during pre-training, and how this process differs from dense architectures, remains unknown. To address this issue, we introduce Gated-LPI (Log-Probability Increase), a neuron-level attribution metric that decomposes log-proba",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Creativity in AI as Emergence from Domain-Limited Generative Models",
      "link": "https://arxiv.org/abs/2601.08388",
      "summary": "arXiv:2601.08388v1 Announce Type: new \nAbstract: Creativity in artificial intelligence is most often addressed through evaluative frameworks that aim to measure novelty, diversity, or usefulness in generated outputs. While such approaches have provided valuable insights into the behavior of modern generative models, they largely treat creativity as a property to be assessed rather than as a phenomenon to be explicitly modeled. In parallel, recent advances in large-scale generative systems, parti",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs",
      "link": "https://arxiv.org/abs/2601.08403",
      "summary": "arXiv:2601.08403v1 Announce Type: new \nAbstract: Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks, but standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when models must infer latent user intent from under-specified language without ground truth labels, a reasoning pattern rarely seen during pretraining. We in",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents",
      "link": "https://arxiv.org/abs/2601.08406",
      "summary": "arXiv:2601.08406v1 Announce Type: new \nAbstract: Web Agents are increasingly deployed to perform complex tasks in real web environments, yet their security evaluation remains fragmented and difficult to standardize. We present WebTrap Park, an automated platform for systematic security evaluation of Web Agents through direct observation of their concrete interactions with live web pages. WebTrap Park instantiates three major sources of security risk into 1,226 executable evaluation tasks and ena",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation",
      "link": "https://arxiv.org/abs/2601.08412",
      "summary": "arXiv:2601.08412v1 Announce Type: new \nAbstract: With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge disti",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation",
      "link": "https://arxiv.org/abs/2601.08430",
      "summary": "arXiv:2601.08430v1 Announce Type: new \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) has driven substantial progress in reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the lack of ground truth. While rubric-based evaluation offers a structured proxy for verification, existing methods suffer from scalability bottlenecks and coarse criteria, resulting in a supervision ceiling effect. To address this, we propose an",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation",
      "link": "https://arxiv.org/abs/2601.08441",
      "summary": "arXiv:2601.08441v1 Announce Type: new \nAbstract: Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference data in a Direct Preference Optimization (DPO) fashion, enabling control over truthfulness, hallucinations, and safety behaviors. However, dense steering ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Beyond Linearization: Attributed Table Graphs for Table Reasoning",
      "link": "https://arxiv.org/abs/2601.08444",
      "summary": "arXiv:2601.08444v1 Announce Type: new \nAbstract: Table reasoning, a task to answer questions by reasoning over data presented in tables, is an important topic due to the prevalence of knowledge stored in tabular formats. Recent solutions use Large Language Models (LLMs), exploiting the semantic understanding and reasoning capabilities of LLMs. A common paradigm of such solutions linearizes tables to form plain texts that are served as input to LLMs. This paradigm has critical issues. It loses ta",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English",
      "link": "https://arxiv.org/abs/2601.08457",
      "summary": "arXiv:2601.08457v1 Announce Type: new \nAbstract: Digital platforms have an ever-expanding user base, and act as a hub for communication, business, and connectivity. However, this has also allowed for the spread of hate speech and misogyny. Artificial intelligence models have emerged as an effective solution for countering online hate speech but are under explored for low resource and code-mixed languages and suffer from a lack of interpretability. Explainable Artificial Intelligence (XAI) can en",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games",
      "link": "https://arxiv.org/abs/2601.08462",
      "summary": "arXiv:2601.08462v1 Announce Type: new \nAbstract: As the capabilities of large language model (LLM) agents continue to advance, their advanced social behaviors, such as cooperation, deception, and collusion, call for systematic evaluation. However, existing benchmarks often emphasize a single capability dimension or rely solely on behavioral outcomes, overlooking rich process information from agents' decision reasoning and communicative interactions. To address this gap, we propose M3-Bench, a mu",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System",
      "link": "https://arxiv.org/abs/2601.08475",
      "summary": "arXiv:2601.08475v1 Announce Type: new \nAbstract: This paper incorporates the efficiency of automatic summarization and addresses the challenge of generating personalized summaries tailored to individual users' interests and requirements. To tackle this challenge, we introduce SummPilot, an interaction-based customizable summarization system. SummPilot leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system to understand docume",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting",
      "link": "https://arxiv.org/abs/2601.08509",
      "summary": "arXiv:2601.08509v1 Announce Type: new \nAbstract: Time series forecasting is critical to real-world decision making, yet most existing approaches remain unimodal and rely on extrapolating historical patterns. While recent progress in large language models (LLMs) highlights the potential for multimodal forecasting, existing benchmarks largely provide retrospective or misaligned raw context, making it unclear whether such models meaningfully leverage textual inputs. In practice, human experts incor",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sketch-Based Facade Renovation With Generative AI: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse",
      "link": "https://arxiv.org/abs/2601.08531",
      "summary": "arXiv:2601.08531v1 Announce Type: new \nAbstract: Facade renovation offers a more sustainable alternative to full demolition, yet producing design proposals that preserve existing structures while expressing new intent remains challenging. Current workflows typically require detailed as-built modelling before design, which is time-consuming, labour-intensive, and often involves repeated revisions. To solve this issue, we propose a three-stage framework combining generative artificial intelligence",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement",
      "link": "https://arxiv.org/abs/2601.08545",
      "summary": "arXiv:2601.08545v1 Announce Type: new \nAbstract: With the development of large language models (LLMs) in the field of programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely \\textbf{LPR} (\\textbf{L}earner-Tailored \\textbf{P}rogram \\textbf{R}epair). We then propose a novel and ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "WaterCopilot: An AI-Driven Virtual Assistant for Water Management",
      "link": "https://arxiv.org/abs/2601.08559",
      "summary": "arXiv:2601.08559v1 Announce Type: new \nAbstract: Sustainable water resource management in transboundary river basins is challenged by fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper presents WaterCopilot-an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge these gaps through a unified, interac",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios",
      "link": "https://arxiv.org/abs/2601.08620",
      "summary": "arXiv:2601.08620v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) pipelines must address challenges beyond simple single-document retrieval, such as interpreting visual elements (tables, charts, images), synthesizing information across documents, and providing accurate source grounding. Existing benchmarks fail to capture this complexity, often focusing on textual data, single-document comprehension, or evaluating retrieval and generation in isolation. We introduce ViDoRe v3,",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning",
      "link": "https://arxiv.org/abs/2601.08641",
      "summary": "arXiv:2601.08641v1 Announce Type: new \nAbstract: The launch of \\$Trump coin ignited a wave in meme coin investment. Copy trading, as a strategy-agnostic approach that eliminates the need for deep trading knowledge, quickly gains widespread popularity in the meme coin market. However, copy trading is not a guarantee of profitability due to the prevalence of manipulative bots, the uncertainty of the followed wallets' future performance, and the lag in trade execution. Recently, large language mode",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding",
      "link": "https://arxiv.org/abs/2601.08653",
      "summary": "arXiv:2601.08653v1 Announce Type: new \nAbstract: Large Language Models are rapidly emerging as web-native interfaces to social platforms. On the social web, users frequently have ambiguous and dynamic goals, making complex intent understanding-rather than single-turn execution-the cornerstone of effective human-LLM collaboration. Existing approaches attempt to clarify user intents through sequential or parallel questioning, yet they fall short of addressing the core challenge: modeling the logic",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner's Tutorial",
      "link": "https://arxiv.org/abs/2601.08662",
      "summary": "arXiv:2601.08662v1 Announce Type: new \nAbstract: This tutorial is designed to make reinforcement learning (RL) more accessible to undergraduate students by offering clear, example-driven explanations. It focuses on bridging the gap between RL theory and practical coding applications, addressing common challenges that students face when transitioning from conceptual understanding to implementation. Through hands-on examples and approachable explanations, the tutorial aims to equip students with t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Parallel Context-of-Experts Decoding for Retrieval Augmented Generation",
      "link": "https://arxiv.org/abs/2601.08670",
      "summary": "arXiv:2601.08670v1 Announce Type: new \nAbstract: Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decoding (Pced), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding. Pced treats retrieved documents as i",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock",
      "link": "https://arxiv.org/abs/2601.08673",
      "summary": "arXiv:2601.08673v1 Announce Type: new \nAbstract: Recent reports of large language models (LLMs) exhibiting behaviors such as deception, threats, or blackmail are often interpreted as evidence of alignment failure or emergent malign agency. We argue that this interpretation rests on a conceptual error. LLMs do not reason morally; they statistically internalize the record of human social interaction, including laws, contracts, negotiations, conflicts, and coercive arrangements. Behaviors commonly ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance",
      "link": "https://arxiv.org/abs/2601.08676",
      "summary": "arXiv:2601.08676v1 Announce Type: new \nAbstract: Environmental, social, and governance (ESG) criteria are essential for evaluating corporate sustainability and ethical performance. However, professional ESG analysis is hindered by data fragmentation across unstructured sources, and existing large language models (LLMs) often struggle with the complex, multi-step workflows required for rigorous auditing. To address these limitations, we introduce ESGAgent, a hierarchical multi-agent system empowe",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning",
      "link": "https://arxiv.org/abs/2601.08679",
      "summary": "arXiv:2601.08679v1 Announce Type: new \nAbstract: As users increasingly expect LLMs to align with their preferences, personalized information becomes valuable. However, personalized information can be a double-edged sword: it can improve interaction but may compromise objectivity and factual correctness, especially when it is misaligned with the question. To alleviate this problem, we propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasonin",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection",
      "link": "https://arxiv.org/abs/2601.08684",
      "summary": "arXiv:2601.08684v1 Announce Type: new \nAbstract: Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communities. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shal",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "All Required, In Order: Phase-Level Evaluation for AI-Human Dialogue in Healthcare and Beyond",
      "link": "https://arxiv.org/abs/2601.08690",
      "summary": "arXiv:2601.08690v1 Announce Type: new \nAbstract: Conversational AI is starting to support real clinical work, but most evaluation methods miss how compliance depends on the full course of a conversation. We introduce Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), an evaluation method that checks whether every required clinical obligation is met, in the right order, with clear evidence for clinicians to review. This makes complex rules practical and auditable, helping cl",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set",
      "link": "https://arxiv.org/abs/2601.08703",
      "summary": "arXiv:2601.08703v1 Announce Type: new \nAbstract: Explainable artificial intelligence (XAI) is concerned with producing explanations indicating the inner workings of models. For a Rashomon set of similarly performing models, explanations provide a way of disambiguating the behavior of individual models, helping select models for deployment. However explanations themselves can vary depending on the explainer used, and need to be evaluated. In the paper \"Evaluating Model Explanations without Ground",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Learning from Demonstrations via Capability-Aware Goal Sampling",
      "link": "https://arxiv.org/abs/2601.08731",
      "summary": "arXiv:2601.08731v1 Announce Type: new \nAbstract: Despite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely on demonstrations only for policy initialization or",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AI as Entertainment",
      "link": "https://arxiv.org/abs/2601.08768",
      "summary": "arXiv:2601.08768v1 Announce Type: new \nAbstract: Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by augmenting or automating human cognitive labor, promising to increase personal, corporate, and macroeconomic productivity. But this mainstream narrative about what AI is and what it can do is in tension with another emerging use case: entertainment. We argue that the field of AI is unprepared to measure or respond to how t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards",
      "link": "https://arxiv.org/abs/2601.08778",
      "summary": "arXiv:2601.08778v1 Announce Type: new \nAbstract: Researchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of database-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial.\n  In this pa",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Uncovering Political Bias in Large Language Models using Parliamentary Voting Records",
      "link": "https://arxiv.org/abs/2601.08785",
      "summary": "arXiv:2601.08785v1 Announce Type: new \nAbstract: As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited, despite their direct societal impact. This paper introduces a general methodology for constructing political bias benchmarks by aligning model-generated voting predicti",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Photometric Redshift Estimation Using Scaled Ensemble Learning",
      "link": "https://arxiv.org/abs/2601.07292",
      "summary": "arXiv:2601.07292v1 Announce Type: cross \nAbstract: The development of the state-of-the-art telescopic systems capable of performing expansive sky surveys such as the Sloan Digital Sky Survey, Euclid, and the Rubin Observatory's Legacy Survey of Space and Time (LSST) has significantly advanced efforts to refine cosmological models. These advances offer deeper insight into persistent challenges in astrophysics and our understanding of the Universe's evolution. A critical component of this progress",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A survey: Information search time optimization based on RAG (Retrieval Augmentation Generation) chatbot",
      "link": "https://arxiv.org/abs/2601.07838",
      "summary": "arXiv:2601.07838v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation (RAG) based chatbots are not only useful for information retrieval through questionanswering but also for making complex decisions based on injected private data.we present a survey on how much search time can be saved when retrieving complex information within an organization called \"X Systems\"(a stealth mode company) by using a RAG-based chatbot compared to traditional search methods. We compare the information r",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Hierarchical Sparse Plus Low Rank Compression of LLM",
      "link": "https://arxiv.org/abs/2601.07839",
      "summary": "arXiv:2601.07839v1 Announce Type: cross \nAbstract: Modern large language models (LLMs) place extraordinary pressure on memory and compute budgets, making principled compression indispensable for both deployment and continued training. We present Hierarchical Sparse Plus Low-Rank (HSS) compression, a two-stage scheme that (i) removes the largest-magnitude weights into a sparse matrix S and (ii) applies a recursive Hierarchically Sparse Separable (HSS) low-rank factorisation to the dense residual ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FinVault: Benchmarking Financial Agent Safety in Execution-Grounded Environments",
      "link": "https://arxiv.org/abs/2601.07853",
      "summary": "arXiv:2601.07853v1 Announce Type: cross \nAbstract: Financial agents powered by large language models (LLMs) are increasingly deployed for investment analysis, risk assessment, and automated decision-making, where their abilities to plan, invoke tools, and manipulate mutable state introduce new security risks in high-stakes and highly regulated financial environments. However, existing safety evaluations largely focus on language-model-level content compliance or abstract agent settings, failing ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Immunological Density Shapes Recovery Trajectories in Long COVID",
      "link": "https://arxiv.org/abs/2601.07854",
      "summary": "arXiv:2601.07854v1 Announce Type: cross \nAbstract: Post-acute sequelae of SARS-CoV-2 infection (Long COVID) frequently persists for months, yet drivers of clinical remission remain incompletely defined.\n  Here we analyzed 97,564 longitudinal PASC assessments from 13,511 participants with linked vaccination histories to disentangle passive temporal progression from vaccine-associated change.\n  Using a clinically validated threshold (PASC $\\geq 12$), trajectories separated into three phenotypes: P",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Empirical Study on Knowledge Transfer under Domain and Label Shifts in 3D LiDAR Point Clouds",
      "link": "https://arxiv.org/abs/2601.07855",
      "summary": "arXiv:2601.07855v1 Announce Type: cross \nAbstract: For 3D perception systems to be practical in real-world applications -- from autonomous driving to embodied AI -- models must adapt to continuously evolving object definitions and sensor domains. Yet, research on continual and transfer learning in 3D point cloud perception remains underexplored compared to 2D vision -- particularly under simultaneous domain and label shifts. To address this gap, we propose the RObust Autonomous driving under Dat",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Feature Entanglement-based Quantum Multimodal Fusion Neural Network",
      "link": "https://arxiv.org/abs/2601.07856",
      "summary": "arXiv:2601.07856v1 Announce Type: cross \nAbstract: Multimodal learning aims to enhance perceptual and decision-making capabilities by integrating information from diverse sources. However, classical deep learning approaches face a critical trade-off between the high accuracy of black-box feature-level fusion and the interpretability of less outstanding decision-level fusion, alongside the challenges of parameter explosion and complexity. This paper discusses the accuracy-interpretablity-complexi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Affect and Effect: Limitations of regularisation-based continual learning in EEG-based emotion classification",
      "link": "https://arxiv.org/abs/2601.07858",
      "summary": "arXiv:2601.07858v1 Announce Type: cross \nAbstract: Generalisation to unseen subjects in EEG-based emotion classification remains a challenge due to high inter-and intra-subject variability. Continual learning (CL) poses a promising solution by learning from a sequence of tasks while mitigating catastrophic forgetting. Regularisation-based CL approaches, such as Elastic Weight Consolidation (EWC), Synaptic Intelligence (SI), and Memory Aware Synapses (MAS), are commonly used as baselines in EEG-b",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "RewriteNets: End-to-End Trainable String-Rewriting for Generative Sequence Modeling",
      "link": "https://arxiv.org/abs/2601.07868",
      "summary": "arXiv:2601.07868v1 Announce Type: cross \nAbstract: Dominant sequence models like the Transformer represent structure implicitly through dense attention weights, incurring quadratic complexity. We propose RewriteNets, a novel neural architecture built on an alternative paradigm: explicit, parallel string rewriting. Each layer in a RewriteNet contains a set of learnable rules. For each position in an input sequence, the layer performs four operations: (1) fuzzy matching of rule patterns, (2) confl",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Imaging-anchored Multiomics in Cardiovascular Disease: Integrating Cardiac Imaging, Bulk, Single-cell, and Spatial Transcriptomics",
      "link": "https://arxiv.org/abs/2601.07871",
      "summary": "arXiv:2601.07871v1 Announce Type: cross \nAbstract: Cardiovascular disease arises from interactions between inherited risk, molecular programmes, and tissue-scale remodelling that are observed clinically through imaging. Health systems now routinely generate large volumes of cardiac MRI, CT and echocardiography together with bulk, single-cell and spatial transcriptomics, yet these data are still analysed in separate pipelines. This review examines joint representations that link cardiac imaging p",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Multiplicative Orthogonal Sequential Editing for Language Models",
      "link": "https://arxiv.org/abs/2601.07873",
      "summary": "arXiv:2601.07873v1 Announce Type: cross \nAbstract: Knowledge editing aims to efficiently modify the internal knowledge of large language models (LLMs) without compromising their other capabilities. The prevailing editing paradigm, which appends an update matrix to the original parameter matrix, has been shown by some studies to damage key numerical stability indicators (such as condition number and norm), thereby reducing editing performance and general abilities, especially in sequential editin",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "NOVAK: Unified adaptive optimizer for deep neural networks",
      "link": "https://arxiv.org/abs/2601.07876",
      "summary": "arXiv:2601.07876v1 Announce Type: cross \nAbstract: This work introduces NOVAK, a modular gradient-based optimization algorithm that integrates adaptive moment estimation, rectified learning-rate scheduling, decoupled weight regularization, multiple variants of Nesterov momentum, and lookahead synchronization into a unified, performance-oriented framework. NOVAK adopts a dual-mode architecture consisting of a streamlined fast path designed for production. The optimizer employs custom CUDA kernels",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "E^2-LLM: Bridging Neural Signals and Interpretable Affective Analysis",
      "link": "https://arxiv.org/abs/2601.07877",
      "summary": "arXiv:2601.07877v1 Announce Type: cross \nAbstract: Emotion recognition from electroencephalography (EEG) signals remains challenging due to high inter-subject variability, limited labeled data, and the lack of interpretable reasoning in existing approaches. While recent multimodal large language models (MLLMs) have advanced emotion analysis, they have not been adapted to handle the unique spatiotemporal characteristics of neural signals. We present E^2-LLM (EEG-to-Emotion Large Language Model), ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sliced-Wasserstein Distribution Alignment Loss Improves the Ultra-Low-Bit Quantization of Large Language Models",
      "link": "https://arxiv.org/abs/2601.07878",
      "summary": "arXiv:2601.07878v1 Announce Type: cross \nAbstract: The benefits of most large language models come with steep and often hidden economic and environmental costs due to their resource usage inefficiency during deployment. Model quantization improves energy and memory efficiency through representing model parameters by lower-precision values. However, compression below 4-bits often distorts activation distributions and degrades performance. We address this challenge by introducing a sliced Wasserst",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sola-Visibility-ISPM: Benchmarking Agentic AI for Identity Security Posture Management Visibility",
      "link": "https://arxiv.org/abs/2601.07880",
      "summary": "arXiv:2601.07880v1 Announce Type: cross \nAbstract: Identity Security Posture Management (ISPM) is a core challenge for modern enterprises operating across cloud and SaaS environments. Answering basic ISPM visibility questions, such as understanding identity inventory and configuration hygiene, requires interpreting complex identity data, motivating growing interest in agentic AI systems. Despite this interest, there is currently no standardized way to evaluate how well such systems perform ISPM ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Tackling Heterogeneity in Quantum Federated Learning: An Integrated Sporadic-Personalized Approach",
      "link": "https://arxiv.org/abs/2601.07882",
      "summary": "arXiv:2601.07882v1 Announce Type: cross \nAbstract: Quantum federated learning (QFL) emerges as a powerful technique that combines quantum computing with federated learning to efficiently process complex data across distributed quantum devices while ensuring data privacy in quantum networks. Despite recent research efforts, existing QFL frameworks struggle to achieve optimal model training performance primarily due to inherent heterogeneity in terms of (i) quantum noise where current quantum devi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Ideological Isolation in Online Social Networks: A Survey of Computational Definitions, Metrics, and Mitigation Strategies",
      "link": "https://arxiv.org/abs/2601.07884",
      "summary": "arXiv:2601.07884v1 Announce Type: cross \nAbstract: The proliferation of online social networks has significantly reshaped the way individuals access and engage with information. While these platforms offer unprecedented connectivity, they may foster environments where users are increasingly exposed to homogeneous content and like-minded interactions. Such dynamics are associated with selective exposure and the emergence of filter bubbles, echo chambers, tunnel vision, and polarization, which tog",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models",
      "link": "https://arxiv.org/abs/2601.07885",
      "summary": "arXiv:2601.07885v1 Announce Type: cross \nAbstract: Emoticons are widely used in digital communication to convey affective intent, yet their safety implications for Large Language Models (LLMs) remain largely unexplored. In this paper, we identify emoticon semantic confusion, a vulnerability where LLMs misinterpret ASCII-based emoticons to perform unintended and even destructive actions. To systematically study this phenomenon, we develop an automated data generation pipeline and construct a data",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "KVzap: Fast, Adaptive, and Faithful KV Cache Pruning",
      "link": "https://arxiv.org/abs/2601.07891",
      "summary": "arXiv:2601.07891v1 Announce Type: cross \nAbstract: Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. While many KV cache pruning methods have been proposed, they have not yet been adopted in major inference engines due to speed--accuracy trade-offs. We introduce KVzap, a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. On Qwen3-8B, Llama-3.1-8B-Instruct, and Qwen3-32B across long",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification",
      "link": "https://arxiv.org/abs/2601.07892",
      "summary": "arXiv:2601.07892v1 Announce Type: cross \nAbstract: The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. While ternary quantization offers a compelling solution by reducing weights to {-1, 0, +1}, current implementations suffer from a fundamental misalignment with commodity hardware. Most existing methods must choose between 2-bit aligned packing, which incurs significant bit wastage, or ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Revealing the Attention Floating Mechanism in Masked Diffusion Models",
      "link": "https://arxiv.org/abs/2601.07894",
      "summary": "arXiv:2601.07894v1 Announce Type: cross \nAbstract: Masked diffusion models (MDMs), which leverage bidirectional attention and a denoising process, are narrowing the performance gap with autoregressive models (ARMs). However, their internal attention mechanisms remain under-explored. This paper investigates the attention behaviors in MDMs, revealing the phenomenon of Attention Floating. Unlike ARMs, where attention converges to a fixed sink, MDMs exhibit dynamic, dispersed attention anchors that ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Large Language Models and Algorithm Execution: Application to an Arithmetic Function",
      "link": "https://arxiv.org/abs/2601.07898",
      "summary": "arXiv:2601.07898v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) have recently developed new advanced functionalities. Their effectiveness relies on statistical learning and generalization capabilities. However, they face limitations in internalizing the data they process and struggle, for instance, to autonomously execute algorithms. In this paper, we investigate the possibility of extending these models' capabilities to algorithm execution through specialized supervised training",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Decentralized Online Convex Optimization with Unknown Feedback Delays",
      "link": "https://arxiv.org/abs/2601.07901",
      "summary": "arXiv:2601.07901v1 Announce Type: cross \nAbstract: Decentralized online convex optimization (D-OCO), where multiple agents within a network collaboratively learn optimal decisions in real-time, arises naturally in applications such as federated learning, sensor networks, and multi-agent control.  In this paper, we study D-OCO under unknown, time-and agent-varying feedback delays. While recent work has addressed this problem (Nguyen et al., 2024), existing algorithms assume prior knowledge of the",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning",
      "link": "https://arxiv.org/abs/2601.07903",
      "summary": "arXiv:2601.07903v1 Announce Type: cross \nAbstract: The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying L",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation",
      "link": "https://arxiv.org/abs/2601.07935",
      "summary": "arXiv:2601.07935v1 Announce Type: cross \nAbstract: The rapid evolution of Large Language Models (LLMs) has shifted focus from general-purpose capabilities to domain-specific expertise. However, adapting LLMs to specialized fields such as medicine presents two challenge: (1) the \"Stability-Plasticity Dilemma\", where the model must acquire complex clinical knowledge without suffering from catastrophic forgetting of general world knowledge; and (2) \"Task Interference\", where disparate sub-tasks, su",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SECite: Analyzing and Summarizing Citations in Software Engineering Literature",
      "link": "https://arxiv.org/abs/2601.07939",
      "summary": "arXiv:2601.07939v1 Announce Type: cross \nAbstract: Identifying the strengths and limitations of a research paper is a core component of any literature review. However, traditional summaries reflect only the authors' self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. In this research, we introduce SECite, a novel approach for evaluating scholarly impact through sentiment ana",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Moonworks Lunara Aesthetic Dataset",
      "link": "https://arxiv.org/abs/2601.07941",
      "summary": "arXiv:2601.07941v1 Announce Type: cross \nAbstract: The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding even aesthe",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Coupled Diffusion-Encoder Models for Reconstruction of Flow Fields",
      "link": "https://arxiv.org/abs/2601.07946",
      "summary": "arXiv:2601.07946v1 Announce Type: cross \nAbstract: Data-driven flow-field reconstruction typically relies on autoencoder architectures that compress high-dimensional states into low-dimensional latent representations. However, classical approaches such as variational autoencoders (VAEs) often struggle to preserve the higher-order statistical structure of fluid flows when subjected to strong compression. We propose DiffCoder, a coupled framework that integrates a probabilistic diffusion model wit",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reinforcement Learning Methods for Neighborhood Selection in Local Search",
      "link": "https://arxiv.org/abs/2601.07948",
      "summary": "arXiv:2601.07948v1 Announce Type: cross \nAbstract: Reinforcement learning has recently gained traction as a means to improve combinatorial optimization methods, yet its effectiveness within local search metaheuristics specifically remains comparatively underexamined. In this study, we evaluate a range of reinforcement learning-based neighborhood selection strategies -- multi-armed bandits (upper confidence bound, $\\epsilon$-greedy) and deep reinforcement learning methods (proximal policy optimiz",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Hybrid SARIMA LSTM Model for Local Weather Forecasting: A Residual Learning Approach for Data Driven Meteorological Prediction",
      "link": "https://arxiv.org/abs/2601.07951",
      "summary": "arXiv:2601.07951v1 Announce Type: cross \nAbstract: Accurately forecasting long-term atmospheric variables remains a defining challenge in meteorological science due to the chaotic nature of atmospheric systems. Temperature data represents a complex superposition of deterministic cyclical climate forces and stochastic, short-term fluctuations. While planetary mechanics drive predictable seasonal periodicities, rapid meteorological changes such as thermal variations, pressure anomalies, and humidi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Quantum automated theorem proving",
      "link": "https://arxiv.org/abs/2601.07953",
      "summary": "arXiv:2601.07953v1 Announce Type: cross \nAbstract: Automated theorem proving, or more broadly automated reasoning, aims at using computer programs to automatically prove or disprove mathematical theorems and logical statements. It takes on an essential role across a vast array of applications and the quest for enhanced theorem-proving capabilities remains a prominent pursuit in artificial intelligence. Here, we propose a generic framework for quantum automated theorem proving, where the intrinsi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices",
      "link": "https://arxiv.org/abs/2601.07957",
      "summary": "arXiv:2601.07957v1 Announce Type: cross \nAbstract: Maize disease classification plays a vital role in mitigating yield losses and ensuring food security. However, the deployment of traditional disease detection models in resource-constrained environments, such as those using smartphones and drones, faces challenges due to high computational costs. To address these challenges, we propose LWMSCNN-SE, a lightweight convolutional neural network (CNN) that integrates multi-scale feature extraction, d",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LJ-Spoof: A Generatively Varied Corpus for Audio Anti-Spoofing and Synthesis Source Tracing",
      "link": "https://arxiv.org/abs/2601.07958",
      "summary": "arXiv:2601.07958v1 Announce Type: cross \nAbstract: Speaker-specific anti-spoofing and synthesis-source tracing are central challenges in audio anti-spoofing. Progress has been hampered by the lack of datasets that systematically vary model architectures, synthesis pipelines, and generative parameters. To address this gap, we introduce LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, train",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Tuberculosis Screening from Cough Audio: Baseline Models, Clinical Variables, and Uncertainty Quantification",
      "link": "https://arxiv.org/abs/2601.07969",
      "summary": "arXiv:2601.07969v1 Announce Type: cross \nAbstract: In this paper, we propose a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. While TB screening from audio has attracted growing interest, progress is difficult to measure because existing studies vary substantially in datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. Consequently, report",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Cultural Compass: A Framework for Organizing Societal Norms to Detect Violations in Human-AI Conversations",
      "link": "https://arxiv.org/abs/2601.07973",
      "summary": "arXiv:2601.07973v1 Announce Type: cross \nAbstract: Generative AI models ought to be useful and safe across cross-cultural contexts. One critical step toward this goal is understanding how AI models adhere to sociocultural norms. While this challenge has gained attention in NLP, existing work lacks both nuance and coverage in understanding and evaluating models' norm adherence. We address these gaps by introducing a taxonomy of norms that clarifies their contexts (e.g., distinguishing between hum",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP",
      "link": "https://arxiv.org/abs/2601.07988",
      "summary": "arXiv:2601.07988v1 Announce Type: cross \nAbstract: While NLP typically treats documents as independent and unordered samples, in longitudinal studies, this assumption rarely holds: documents are nested within authors and ordered in time, forming person-indexed, time-ordered $\\textit{behavioral sequences}$. Here, we demonstrate the need for and propose a longitudinal modeling and evaluation paradigm that consequently updates four parts of the NLP pipeline: (1) evaluation splits aligned to general",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs",
      "link": "https://arxiv.org/abs/2601.07994",
      "summary": "arXiv:2601.07994v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. However, existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. We introduce DyCP, a lightweight context management ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback",
      "link": "https://arxiv.org/abs/2601.08003",
      "summary": "arXiv:2601.08003v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. We introduce LLM Review, a peer-review-inspired framework implementing Blind Peer Review: agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. To enable rigorous evaluation, we propo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models",
      "link": "https://arxiv.org/abs/2601.08011",
      "summary": "arXiv:2601.08011v1 Announce Type: cross \nAbstract: Current text-conditioned diffusion editors handle single object replacement well but struggle when a new object and a new style must be introduced simultaneously. We present Twin-Prompt Attention Blend (TP-Blend), a lightweight training-free framework that receives two separate textual prompts, one specifying a blend object and the other defining a target style, and injects both into a single denoising trajectory. TP-Blend is driven by two compl",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Representations of Text and Images Align From Layer One",
      "link": "https://arxiv.org/abs/2601.08017",
      "summary": "arXiv:2601.08017v1 Announce Type: cross \nAbstract: We show that for a variety of concepts in adapter-based vision-language models, the representations of their images and their text descriptions are meaningfully aligned from the very first layer. This contradicts the established view that such image-text alignment only appears in late layers. We show this using a new synthesis-based method inspired by DeepDream: given a textual concept such as \"Jupiter\", we extract its concept vector at a given ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures",
      "link": "https://arxiv.org/abs/2601.08026",
      "summary": "arXiv:2601.08026v1 Announce Type: cross \nAbstract: Scientific compound figures combine multiple labeled panels into a single image, but captions in real pipelines are often missing or only provide figure-level summaries, making panel-level understanding difficult. In this paper, we propose FigEx2, visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. To mitigate the impact of diverse phrasing in open-ended captioning, we introduce",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Role of Noisy Data in Improving CNN Robustness for Image Classification",
      "link": "https://arxiv.org/abs/2601.08043",
      "summary": "arXiv:2601.08043v1 Announce Type: cross \nAbstract: Data quality plays a central role in the performance and robustness of convolutional neural networks (CNNs) for image classification. While high-quality data is often preferred for training, real-world inputs are frequently affected by noise and other distortions. This paper investigates the effect of deliberately introducing controlled noise into the training data to improve model robustness. Using the CIFAR-10 dataset, we evaluate the impact o",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models",
      "link": "https://arxiv.org/abs/2601.08058",
      "summary": "arXiv:2601.08058v1 Announce Type: cross \nAbstract: Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in large language models. In this work, we study this question by directly analyzing and intervening on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features that are causally associate",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment",
      "link": "https://arxiv.org/abs/2601.08089",
      "summary": "arXiv:2601.08089v1 Announce Type: cross \nAbstract: Public large language models (LLMs) are typically safety-aligned during pretraining, yet task-specific fine-tuning required for deployment often erodes this alignment and introduces safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on fine-tuning-derived priors for post-hoc correction, leaving safety recovery tightly coupled with training and incurring high computational overhead and a complex workflow. To add",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition",
      "link": "https://arxiv.org/abs/2601.08094",
      "summary": "arXiv:2601.08094v1 Announce Type: cross \nAbstract: Subject-independent EEG emotion recognition is challenged by pronounced inter-subject variability and the difficulty of learning robust representations from short, noisy recordings. To address this, we propose a fusion framework that integrates (i) local, channel-wise descriptors and (ii) global, trial-level descriptors, improving cross-subject generalization on the SEED-VII dataset. Local representations are formed per channel by concatenating ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "High-Fidelity Modeling of Stochastic Chemical Dynamics on Complex Manifolds: A Multi-Scale SIREN-PINN Framework for the Curvature-Perturbed Ginzburg-Landau Equation",
      "link": "https://arxiv.org/abs/2601.08104",
      "summary": "arXiv:2601.08104v1 Announce Type: cross \nAbstract: The accurate identification and control of spatiotemporal chaos in reaction-diffusion systems remains a grand challenge in chemical engineering, particularly when the underlying catalytic surface possesses complex, unknown topography. In the \\textit{Defect Turbulence} regime, system dynamics are governed by topological phase singularities (spiral waves) whose motion couples to manifold curvature via geometric pinning. Conventional Physics-Inform",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order",
      "link": "https://arxiv.org/abs/2601.08107",
      "summary": "arXiv:2601.08107v1 Announce Type: cross \nAbstract: Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions, but it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on im",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought",
      "link": "https://arxiv.org/abs/2601.08108",
      "summary": "arXiv:2601.08108v1 Announce Type: cross \nAbstract: Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adap",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CSQL: Mapping Documents into Causal Databases",
      "link": "https://arxiv.org/abs/2601.08109",
      "summary": "arXiv:2601.08109v1 Announce Type: cross \nAbstract: We describe a novel system, CSQL, which automatically converts a collection of unstructured text documents into an SQL-queryable causal database (CDB). A CDB differs from a traditional DB: it is designed to answer \"why'' questions via causal interventions and structured causal queries. CSQL builds on our earlier system, DEMOCRITUS, which converts documents into thousands of local causal models derived from causal discourse. Unlike RAG-based syst",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images",
      "link": "https://arxiv.org/abs/2601.08127",
      "summary": "arXiv:2601.08127v1 Announce Type: cross \nAbstract: The development of robust artificial intelligence models for histopathology diagnosis is severely constrained by the scarcity of expert-annotated lesion data, particularly for rare pathologies and underrepresented disease subtypes. While data augmentation offers a potential solution, existing methods fail to generate sufficiently realistic lesion morphologies that preserve the complex spatial relationships and cellular architectures characterist",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?",
      "link": "https://arxiv.org/abs/2601.08133",
      "summary": "arXiv:2601.08133v1 Announce Type: cross \nAbstract: Audio-visual semantic segmentation (AVSS) represents an extension of the audio-visual segmentation (AVS) task, necessitating a semantic understanding of audio-visual scenes beyond merely identifying sound-emitting objects at the visual pixel level. Contrary to a previous methodology, by decomposing the AVSS task into two discrete subtasks by initially providing a prompted segmentation mask to facilitate subsequent semantic analysis, our approach",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Subspace Alignment for Vision-Language Model Test-time Adaptation",
      "link": "https://arxiv.org/abs/2601.08139",
      "summary": "arXiv:2601.08139v1 Announce Type: cross \nAbstract: Vision-language models (VLMs), despite their extraordinary zero-shot capabilities, are vulnerable to distribution shifts. Test-time adaptation (TTA) emerges as a predominant strategy to adapt VLMs to unlabeled test data on the fly. However, existing TTA methods heavily rely on zero-shot predictions as pseudo-labels for self-training, which can be unreliable under distribution shifts and misguide adaptation due to two fundamental limitations. Fir",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training",
      "link": "https://arxiv.org/abs/2601.08141",
      "summary": "arXiv:2601.08141v1 Announce Type: cross \nAbstract: Despite remarkable progress in large language models, Urdu-a language spoken by over 230 million people-remains critically underrepresented in modern NLP systems. Existing multilingual models demonstrate poor performance on Urdu-specific tasks, struggling with the language's complex morphology, right-to-left Nastaliq script, and rich literary traditions. Even the base LLaMA-3.1 8B-Instruct model shows limited capability in generating fluent, con",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Mechanisms are Transferable: Data-Efficient Low-Resource Adaptation via Circuit-Targeted Supervised Fine-Tuning",
      "link": "https://arxiv.org/abs/2601.08146",
      "summary": "arXiv:2601.08146v1 Announce Type: cross \nAbstract: Adapting LLMs to low-resource languages is difficult: labeled data is scarce, full-model fine-tuning is unstable, and continued cross-lingual tuning can cause catastrophic forgetting. We propose Circuit-Targeted Supervised Fine-Tuning (CT-SFT): a counterfactual-free adaptation of CD-T (Contextual Decomposition Transformer) that uses a label-balanced mean baseline and task-directional relevance scoring to identify a sparse set of task-relevant at",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Enriching Semantic Profiles into Knowledge Graph for Recommender Systems Using Large Language Models",
      "link": "https://arxiv.org/abs/2601.08148",
      "summary": "arXiv:2601.08148v1 Announce Type: cross \nAbstract: Rich and informative profiling to capture user preferences is essential for improving recommendation quality. However, there is still no consensus on how best to construct and utilize such profiles. To address this, we revisit recent profiling-based approaches in recommender systems along four dimensions: 1) knowledge base, 2) preference indicator, 3) impact range, and 4) subject. We argue that large language models (LLMs) are effective at extra",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Dynamic Graph Structure Learning via Resistance Curvature Flow",
      "link": "https://arxiv.org/abs/2601.08149",
      "summary": "arXiv:2601.08149v1 Announce Type: cross \nAbstract: Geometric Representation Learning (GRL) aims to approximate the non-Euclidean topology of high-dimensional data through discrete graph structures, grounded in the manifold hypothesis. However, traditional static graph construction methods based on Euclidean distance often fail to capture the intrinsic curvature characteristics of the data manifold. Although Ollivier-Ricci Curvature Flow (OCF) has proven to be a powerful tool for dynamic topologi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SwiftMem: Fast Agentic Memory via Query-aware Indexing",
      "link": "https://arxiv.org/abs/2601.08160",
      "summary": "arXiv:2601.08160v1 Announce Type: cross \nAbstract: Agentic memory systems have become critical for enabling LLM agents to maintain long-term context and retrieve relevant information efficiently. However, existing memory frameworks suffer from a fundamental limitation: they perform exhaustive retrieval across the entire storage layer regardless of query characteristics. This brute-force approach creates severe latency bottlenecks as memory grows, hindering real-time agent interactions. We propos",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering",
      "link": "https://arxiv.org/abs/2601.08176",
      "summary": "arXiv:2601.08176v1 Announce Type: cross \nAbstract: Automatic evaluation of large language model (LLM) responses requires not only factual correctness but also clarity, particularly in political question-answering. While recent datasets provide human annotations for clarity and evasion, the impact of prompt design on automatic clarity evaluation remains underexplored. In this paper, we study prompt-based clarity evaluation using the CLARITY dataset from the SemEval 2026 shared task. We compare a ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Instruction-Driven 3D Facial Expression Generation and Transition",
      "link": "https://arxiv.org/abs/2601.08179",
      "summary": "arXiv:2601.08179v1 Announce Type: cross \nAbstract: A 3D avatar typically has one of six cardinal facial expressions. To simulate realistic emotional variation, we should be able to render a facial transition between two arbitrary expressions. This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and, starting from an image of the face, transforms the facial expression from one designated facial expression to another. The Instruction-drive",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards",
      "link": "https://arxiv.org/abs/2601.08183",
      "summary": "arXiv:2601.08183v1 Announce Type: cross \nAbstract: Multimodal Large Language Models (MLLMs) show promise in gastroenterology, yet their performance against comprehensive clinical workflows and human benchmarks remains unverified. To systematically evaluate state-of-the-art MLLMs across a panoramic gastrointestinal endoscopy workflow and determine their clinical utility compared with human endoscopists. We constructed GI-Bench, a benchmark encompassing 20 fine-grained lesion categories. Twelve ML",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning",
      "link": "https://arxiv.org/abs/2601.08185",
      "summary": "arXiv:2601.08185v1 Announce Type: cross \nAbstract: Autonomous experimentation holds the potential to accelerate materials development by combining artificial intelligence (AI) with modular robotic platforms to explore extensive combinatorial chemical and processing spaces. Such self-driving laboratories can not only increase the throughput of repetitive experiments, but also incorporate human domain expertise to drive the search towards user-defined objectives, including improved materials perfo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ForgetMark: Stealthy Fingerprint Embedding via Targeted Unlearning in Language Models",
      "link": "https://arxiv.org/abs/2601.08189",
      "summary": "arXiv:2601.08189v1 Announce Type: cross \nAbstract: Existing invasive (backdoor) fingerprints suffer from high-perplexity triggers that are easily filtered, fixed response patterns exposed by heuristic detectors, and spurious activations on benign inputs. We introduce \\textsc{ForgetMark}, a stealthy fingerprinting framework that encodes provenance via targeted unlearning. It builds a compact, human-readable key--value set with an assistant model and predictive-entropy ranking, then trains lightwe",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis",
      "link": "https://arxiv.org/abs/2601.08196",
      "summary": "arXiv:2601.08196v1 Announce Type: cross \nAbstract: The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. However, existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To fill this gap, we introduce LogiSafetyGen, a framew",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection",
      "link": "https://arxiv.org/abs/2601.08223",
      "summary": "arXiv:2601.08223v1 Announce Type: cross \nAbstract: The rapid growth of large language models raises pressing concerns about intellectual property protection under black-box deployment. Existing backdoor-based fingerprints either rely on rare tokens -- leading to high-perplexity inputs susceptible to filtering -- or use fixed trigger-response mappings that are brittle to leakage and post-hoc adaptation. We propose \\textsc{Dual-Layer Nested Fingerprinting} (DNF), a black-box method that embeds a h",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Knowledge-based learning in Text-RAG and Image-RAG",
      "link": "https://arxiv.org/abs/2601.08226",
      "summary": "arXiv:2601.08226v1 Announce Type: cross \nAbstract: This research analyzed and compared the multi-modal approach in the Vision Transformer(EVA-ViT) based image encoder with the LlaMA or ChatGPT LLM to reduce the hallucination problem and detect diseases in chest x-ray images. In this research, we utilized the NIH Chest X-ray image to train the model and compared it in image-based RAG, text-based RAG, and baseline. [3] [5] In a result, the text-based RAG[2] e!ectively reduces the hallucination pro",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "GADPN: Graph Adaptive Denoising and Perturbation Networks via Singular Value Decomposition",
      "link": "https://arxiv.org/abs/2601.08230",
      "summary": "arXiv:2601.08230v1 Announce Type: cross \nAbstract: While Graph Neural Networks (GNNs) excel on graph-structured data, their performance is fundamentally limited by the quality of the observed graph, which often contains noise, missing links, or structural properties misaligned with GNNs' underlying assumptions. To address this, graph structure learning aims to infer a more optimal topology. Existing methods, however, often incur high computational costs due to complex generative models and itera",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Hyperbolic Heterogeneous Graph Transformer",
      "link": "https://arxiv.org/abs/2601.08251",
      "summary": "arXiv:2601.08251v1 Announce Type: cross \nAbstract: In heterogeneous graphs, we can observe complex structures such as tree-like or hierarchical structures. Recently, the hyperbolic space has been widely adopted in many studies to effectively learn these complex structures. Although these methods have demonstrated the advantages of the hyperbolic space in learning heterogeneous graphs, most existing methods still have several challenges. They rely heavily on tangent-space operations, which often ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "On Evaluation of Unsupervised Feature Selection for Pattern Classification",
      "link": "https://arxiv.org/abs/2601.08257",
      "summary": "arXiv:2601.08257v1 Announce Type: cross \nAbstract: Unsupervised feature selection aims to identify a compact subset of features that captures the intrinsic structure of data without supervised label. Most existing studies evaluate the performance of methods using the single-label dataset that can be instantiated by selecting a label from multi-label data while maintaining the original features. Because the chosen label can vary arbitrarily depending on the experimental setting, the superiority a",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding",
      "link": "https://arxiv.org/abs/2601.08273",
      "summary": "arXiv:2601.08273v1 Announce Type: cross \nAbstract: Speculative decoding (SD) has emerged as a promising approach to accelerate LLM inference without sacrificing output quality. Existing SD methods tailored for video-LLMs primarily focus on pruning redundant visual tokens to mitigate the computational burden of massive visual inputs. However, existing methods do not achieve inference acceleration comparable to text-only LLMs. We observe from extensive experiments that this phenomenon mainly stems",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Demystifying the Slash Pattern in Attention: The Role of RoPE",
      "link": "https://arxiv.org/abs/2601.08297",
      "summary": "arXiv:2601.08297v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the $\\Delta$-th sub-diagonal for some offset $\\Delta$. These patterns play a key role in passing information across tokens. But why do they emerge? In this paper, we demystify the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. First, by analyzing open-source LLMs, we find that SDHs are in",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques",
      "link": "https://arxiv.org/abs/2601.08302",
      "summary": "arXiv:2601.08302v1 Announce Type: cross \nAbstract: This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning",
      "link": "https://arxiv.org/abs/2601.08310",
      "summary": "arXiv:2601.08310v1 Announce Type: cross \nAbstract: Recent Large Reasoning Models (LRMs) achieve strong performance by leveraging long-form Chain-of-Thought (CoT) reasoning, but uniformly applying overlong reasoning at inference time incurs substantial and often unnecessary computational cost. To address this, prior work explores various strategies to infer an appropriate reasoning budget from the input. However, such approaches are unreliable in the worst case, as estimating the minimal required",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation",
      "link": "https://arxiv.org/abs/2601.08311",
      "summary": "arXiv:2601.08311v1 Announce Type: cross \nAbstract: Large Multimodal Models (LMMs) have recently shown remarkable promise in low-level visual perception tasks, particularly in Image Quality Assessment (IQA), demonstrating strong zero-shot capability. However, achieving state-of-the-art performance often requires computationally expensive fine-tuning methods, which aim to align the distribution of quality-related token in output with image quality levels. Inspired by recent training-free works for",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Safe Heterogeneous Multi-Agent RL with Communication Regularization for Coordinated Target Acquisition",
      "link": "https://arxiv.org/abs/2601.08327",
      "summary": "arXiv:2601.08327v1 Announce Type: cross \nAbstract: This paper introduces a decentralized multi-agent reinforcement learning framework enabling structurally heterogeneous teams of agents to jointly discover and acquire randomly located targets in environments characterized by partial observability, communication constraints, and dynamic interactions. Each agent's policy is trained with the Multi-Agent Proximal Policy Optimization algorithm and employs a Graph Attention Network encoder that integr",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "IGAN: A New Inception-based Model for Stable and High-Fidelity Image Synthesis Using Generative Adversarial Networks",
      "link": "https://arxiv.org/abs/2601.08332",
      "summary": "arXiv:2601.08332v1 Announce Type: cross \nAbstract: Generative Adversarial Networks (GANs) face a significant challenge of striking an optimal balance between high-quality image generation and training stability. Recent techniques, such as DCGAN, BigGAN, and StyleGAN, improve visual fidelity; however, such techniques usually struggle with mode collapse and unstable gradients at high network depth. This paper proposes a novel GAN structural model that incorporates deeper inception-inspired convolu",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Scalable Sequential Recommendation under Latency and Memory Constraints",
      "link": "https://arxiv.org/abs/2601.08360",
      "summary": "arXiv:2601.08360v1 Announce Type: cross \nAbstract: Sequential recommender systems must model long-range user behavior while operating under strict memory and latency constraints. Transformer-based approaches achieve strong accuracy but suffer from quadratic attention complexity, forcing aggressive truncation of user histories and limiting their practicality for long-horizon modeling. This paper presents HoloMambaRec, a lightweight sequential recommendation architecture that combines holographic ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild with an SDF Renderer",
      "link": "https://arxiv.org/abs/2601.08371",
      "summary": "arXiv:2601.08371v1 Announce Type: cross \nAbstract: We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. While existing in-the-wild methods already excel at novel view synthesis, they often lack geometric grounding on complex surfaces, sometimes producing results that contain inconsistencies. Geo-NVS-w addresses this limitation by leveraging an underlying geometric representation based on a Signed Distance Func",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance",
      "link": "https://arxiv.org/abs/2601.08379",
      "summary": "arXiv:2601.08379v1 Announce Type: cross \nAbstract: Pre-trained diffusion models have emerged as powerful generative priors for both unconditional and conditional sample generation, yet their outputs often deviate from the characteristics of user-specific target data. Such mismatches are especially problematic in domain adaptation tasks, where only a few reference examples are available and retraining the diffusion model is infeasible. Existing inference-time guidance methods can adjust sampling ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Controlled LLM Training on Spectral Sphere",
      "link": "https://arxiv.org/abs/2601.08393",
      "summary": "arXiv:2601.08393v1 Announce Type: cross \nAbstract: Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization ($\\boldsymbol{\\mu}$P) provides a theoretical safeguard for width-invariant $\\Theta(1)$ activation control, whereas emerging optimizers like Muon are only ``half-aligned'' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the \\textbf{Spectral Spher",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Explainable Two Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50",
      "link": "https://arxiv.org/abs/2601.08401",
      "summary": "arXiv:2601.08401v1 Announce Type: cross \nAbstract: Objectives: To overcome challenges in diagnosing pericoronitis on panoramic radiographs, an AI-assisted assessment system integrating anatomical localization, pathological classification, and interpretability. Methods: A two-stage deep learning pipeline was implemented. The first stage used YOLOv8 to detect third molars and classify their anatomical positions and angulations based on Winter's classification. Detected regions were then fed into a",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors",
      "link": "https://arxiv.org/abs/2601.08402",
      "summary": "arXiv:2601.08402v1 Announce Type: cross \nAbstract: Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Despite this, current LLM tutoring systems do not take into account student personality traits. To address this problem, we first construct a taxonomy that links pedagogical methods to personality profiles, ba",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Regulatory gray areas of LLM Terms",
      "link": "https://arxiv.org/abs/2601.08415",
      "summary": "arXiv:2601.08415v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are increasingly integrated into academic research pipelines; however, the Terms of Service governing their use remain under-examined. We present a comparative analysis of the Terms of Service of five major LLM providers (Anthropic, DeepSeek, Google, OpenAI, and xAI) collected in November 2025. Our analysis reveals substantial variation in the stringency and specificity of usage restrictions for general users and res",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance",
      "link": "https://arxiv.org/abs/2601.08418",
      "summary": "arXiv:2601.08418v1 Announce Type: cross \nAbstract: Tax code prediction is a crucial yet underexplored task in automating invoicing and compliance management for large-scale e-commerce platforms. Each product must be accurately mapped to a node within a multi-level taxonomic hierarchy defined by national standards, where errors lead to financial inconsistencies and regulatory risks. This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction.",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Large Multimodal Models for Embodied Intelligent Driving: The Next Frontier in Self-Driving?",
      "link": "https://arxiv.org/abs/2601.08434",
      "summary": "arXiv:2601.08434v1 Announce Type: cross \nAbstract: The advent of Large Multimodal Models (LMMs) offers a promising technology to tackle the limitations of modular design in autonomous driving, which often falters in open-world scenarios requiring sustained environmental understanding and logical reasoning. Besides, embodied artificial intelligence facilitates policy optimization through closed-loop interactions to achieve the continuous learning capability, thereby advancing autonomous driving t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning",
      "link": "https://arxiv.org/abs/2601.08448",
      "summary": "arXiv:2601.08448v1 Announce Type: cross \nAbstract: Few-shot class-incremental learning (FSCIL) aims to continuously recognize novel classes under limited data, which suffers from the key stability-plasticity dilemma: balancing the retention of old knowledge with the acquisition of new knowledge. To address this issue, we divide the task into two different stages and propose a framework termed Static-Dynamic Collaboration (SDC) to achieve a better trade-off between stability and plasticity. Speci",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Decoding Order Matters in Autoregressive Speech Synthesis",
      "link": "https://arxiv.org/abs/2601.08450",
      "summary": "arXiv:2601.08450v1 Announce Type: cross \nAbstract: Autoregressive speech synthesis often adopts a left-to-right order, yet generation order is a modelling choice. We investigate decoding order through masked diffusion framework, which progressively unmasks positions and allows arbitrary decoding orders during training and inference. By interpolating between identity and random permutations, we show that randomness in decoding order affects speech quality. We further compare fixed strategies, suc",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Formal Proof of a Continued Fraction Conjecture for $\\pi$ Originating from the Ramanujan Machine",
      "link": "https://arxiv.org/abs/2601.08461",
      "summary": "arXiv:2601.08461v1 Announce Type: cross \nAbstract: We provide a formal analytic proof for a class of non-canonical polynomial continued fractions representing {\\pi}/4, originally conjectured by the Ramanujan Machine using algorithmic induction [4]. By establishing an explicit correspondence with the ratio of contiguous Gaussian hypergeometric functions 2F1(a, b; c; z), we show that these identities can be derived via a discrete sequence of equivalence transformations. We further prove that the c",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CoMa: Contextual Massing Generation with Vision-Language Models",
      "link": "https://arxiv.org/abs/2601.08464",
      "summary": "arXiv:2601.08464v1 Announce Type: cross \nAbstract: The conceptual design phase in architecture and urban planning, particularly building massing, is complex and heavily reliant on designer intuition and manual effort. To address this, we propose an automated framework for generating building massing based on functional requirements and site context. A primary obstacle to such data-driven methods has been the lack of suitable datasets. Consequently, we introduce the CoMa-20K dataset, a comprehens",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "JudgeRLVR: Judge First, Generate Second for Efficient Reasoning",
      "link": "https://arxiv.org/abs/2601.08468",
      "summary": "arXiv:2601.08468v1 Announce Type: cross \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reaso",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "sui-1: Grounded and Verifiable Long-Form Summarization",
      "link": "https://arxiv.org/abs/2601.08472",
      "summary": "arXiv:2601.08472v1 Announce Type: cross \nAbstract: Large language models frequently generate plausible but unfaithful summaries that users cannot verify against source text, a critical limitation in compliance-sensitive domains such as government and legal analysis. We present sui-1, a 24B parameter model that produces abstractive summaries with inline citations, enabling users to trace each claim to its source sentence. Our synthetic data pipeline combines chain-of-thought prompting with multi-",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts",
      "link": "https://arxiv.org/abs/2601.08490",
      "summary": "arXiv:2601.08490v1 Announce Type: cross \nAbstract: We investigate a failure mode of large language models (LLMs) in which plain-text prompts elicit excessive outputs, a phenomenon we term Overflow. Unlike jailbreaks or prompt injection, Overflow arises under ordinary interaction settings and can lead to elevated serving cost, latency, and cross-user performance degradation, particularly when scaled across many requests. Beyond usability, the stakes are economic and environmental: unnecessary tok",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PKI: Prior Knowledge-Infused Neural Network for Few-Shot Class-Incremental Learning",
      "link": "https://arxiv.org/abs/2601.08493",
      "summary": "arXiv:2601.08493v1 Announce Type: cross \nAbstract: Few-shot class-incremental learning (FSCIL) aims to continually adapt a model on a limited number of new-class examples, facing two well-known challenges: catastrophic forgetting and overfitting to new classes. Existing methods tend to freeze more parts of network components and finetune others with an extra memory during incremental sessions. These methods emphasize preserving prior knowledge to ensure proficiency in recognizing old classes, th",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers",
      "link": "https://arxiv.org/abs/2601.08499",
      "summary": "arXiv:2601.08499v1 Announce Type: cross \nAbstract: Large models such as Vision Transformers (ViTs) have demonstrated remarkable superiority over smaller architectures like ResNet in few-shot classification, owing to their powerful representational capacity. However, fine-tuning such large models demands extensive GPU memory and prolonged training time, making them impractical for many real-world low-resource scenarios. To bridge this gap, we propose EfficientFSL, a query-only fine-tuning framewo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care",
      "link": "https://arxiv.org/abs/2601.08503",
      "summary": "arXiv:2601.08503v1 Announce Type: cross \nAbstract: We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives. We analysed TFN in post-kidney transplant (KTx) care, with a retrospective cohort of 3382 patients, on three key outcomes: graft loss, graft rejection, and mortality. Compared to state-of-the-art model in post KTx care, TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94)",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays",
      "link": "https://arxiv.org/abs/2601.08510",
      "summary": "arXiv:2601.08510v1 Announce Type: cross \nAbstract: Movie screenplays are rich long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. While prior benchmarks target individual subtasks such as question answering or dialogue generation, they rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. We introduce STAGE (Screenplay Text, Agent",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CD^2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning",
      "link": "https://arxiv.org/abs/2601.08519",
      "summary": "arXiv:2601.08519v1 Announce Type: cross \nAbstract: Few-shot class-incremental learning (FSCIL) receives significant attention from the public to perform classification continuously with a few training samples, which suffers from the key catastrophic forgetting problem. Existing methods usually employ an external memory to store previous knowledge and treat it with incremental classes equally, which cannot properly preserve previous essential knowledge. To solve this problem and inspired by recen",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical Signatures",
      "link": "https://arxiv.org/abs/2601.08549",
      "summary": "arXiv:2601.08549v1 Announce Type: cross \nAbstract: We introduce a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor ima",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations",
      "link": "https://arxiv.org/abs/2601.08557",
      "summary": "arXiv:2601.08557v1 Announce Type: cross \nAbstract: Hallucinations in video-capable vision-language models (Video-VLMs) remain frequent and high-confidence, while existing uncertainty metrics often fail to align with correctness. We introduce VideoHEDGE, a modular framework for hallucination detection in video question answering that extends entropy-based reliability estimation from images to temporally structured inputs. Given a video-question pair, VideoHEDGE draws a baseline answer and multipl",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Rewriting Video: Text-Driven Reauthoring of Video Footage",
      "link": "https://arxiv.org/abs/2601.08565",
      "summary": "arXiv:2601.08565v1 Announce Type: cross \nAbstract: Video is a powerful medium for communication and storytelling, yet reauthoring existing footage remains challenging. Even simple edits often demand expertise, time, and careful planning, constraining how creators envision and shape their narratives. Recent advances in generative AI suggest a new paradigm: what if editing a video were as straightforward as rewriting text? To investigate this, we present a tech probe and a study on text-driven vid",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation",
      "link": "https://arxiv.org/abs/2601.08602",
      "summary": "arXiv:2601.08602v1 Announce Type: cross \nAbstract: Vision modeling has advanced rapidly with Transformers, whose attention mechanisms capture visual dependencies but lack a principled account of how semantic information propagates spatially. We revisit this problem from a wave-based perspective: feature maps are treated as spatial signals whose evolution over an internal propagation time (aligned with network depth) is governed by an underdamped wave equation. In this formulation, spatial freque",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ExpSeek: Self-Triggered Experience Seeking for Web Agents",
      "link": "https://arxiv.org/abs/2601.08605",
      "summary": "arXiv:2601.08605v1 Announce Type: cross \nAbstract: Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations during agent-environment interaction. We propose ExpSeek, which shifts experience toward ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VeriTaS: The First Dynamic Benchmark for Multimodal Automated Fact-Checking",
      "link": "https://arxiv.org/abs/2601.08611",
      "summary": "arXiv:2601.08611v1 Announce Type: cross \nAbstract: The growing scale of online misinformation urgently demands Automated Fact-Checking (AFC). Existing benchmarks for evaluating AFC systems, however, are largely limited in terms of task scope, modalities, domain, language diversity, realism, or coverage of misinformation types. Critically, they are static, thus subject to data leakage as their claims enter the pretraining corpora of LLMs. As a result, benchmark performance no longer reliably refl",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models",
      "link": "https://arxiv.org/abs/2601.08623",
      "summary": "arXiv:2601.08623v1 Announce Type: cross \nAbstract: Image generation models (IGMs), while capable of producing impressive and creative content, often memorize a wide range of undesirable concepts from their training data, leading to the reproduction of unsafe content such as NSFW imagery and copyrighted artistic styles. Such behaviors pose persistent safety and compliance risks in real-world deployments and cannot be reliably mitigated by post-hoc filtering, owing to the limited robustness of suc",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "M$^2$FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting",
      "link": "https://arxiv.org/abs/2601.08631",
      "summary": "arXiv:2601.08631v1 Announce Type: cross \nAbstract: Forecasting time series with extreme events is critical yet challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. While existing methods excel in modeling dominant regular patterns, their performance degrades significantly during extreme events, constituting the primary source of forecasting errors in real-world applications. Although some approaches incorporate auxiliary signals to improve performance, t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs",
      "link": "https://arxiv.org/abs/2601.08634",
      "summary": "arXiv:2601.08634v1 Announce Type: cross \nAbstract: While recent research has systematically documented political orientation in large language models (LLMs), existing evaluations rely primarily on direct probing or demographic persona engineering to surface ideological biases. In social psychology, however, political ideology is also understood as a downstream consequence of fundamental moral intuitions. In this work, we investigate the causal relationship between moral values and political posi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation",
      "link": "https://arxiv.org/abs/2601.08654",
      "summary": "arXiv:2601.08654v1 Announce Type: cross \nAbstract: The LLM-as-a-Judge paradigm promises scalable rubric-based evaluation, yet aligning frozen black-box models with human standards remains a challenge due to inherent generation stochasticity. We reframe judge alignment as a criteria transfer problem and isolate three recurrent failure modes: rubric instability caused by prompt sensitivity, unverifiable reasoning that lacks auditable evidence, and scale misalignment with human grading boundaries. ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations",
      "link": "https://arxiv.org/abs/2601.08659",
      "summary": "arXiv:2601.08659v1 Announce Type: cross \nAbstract: Detecting anomalies in high-dimensional, time-dependent simulation data is challenging due to complex spatial and temporal dynamics. We study reconstruction-based anomaly detection for ensemble data from parameterized K\\'arm\\'an vortex street simulations using convolutional autoencoders. We compare a 2D autoencoder operating on individual frames with a 3D autoencoder that processes short temporal stacks. The 2D model identifies localized spatial",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization",
      "link": "https://arxiv.org/abs/2601.08682",
      "summary": "arXiv:2601.08682v1 Announce Type: cross \nAbstract: Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. However, automatically generating high-quality summaries is challenging, as the ideal summary must satisfy a set of complex, multi-faceted requirements. While summarization has received immense attention in research, prior work has primarily utilized static datasets and benchmarks, a conditi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Region of interest detection for efficient aortic segmentation",
      "link": "https://arxiv.org/abs/2601.08683",
      "summary": "arXiv:2601.08683v1 Announce Type: cross \nAbstract: Thoracic aortic dissection and aneurysms are the most lethal diseases of the aorta. The major hindrance to treatment lies in the accurate analysis of the medical images. More particularly, aortic segmentation of the 3D image is often tedious and difficult. Deep-learning-based segmentation models are an ideal solution, but their inability to deliver usable outputs in difficult cases and their computational cost cause their clinical adoption to st",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students",
      "link": "https://arxiv.org/abs/2601.08697",
      "summary": "arXiv:2601.08697v1 Announce Type: cross \nAbstract: As generative AI becomes embedded in higher education, it increasingly shapes how students complete academic tasks. While these systems offer efficiency and support, concerns persist regarding over-automation, diminished student agency, and the potential for unreliable or hallucinated outputs. This study conducts a mixed-methods audit of student-AI collaboration preferences by examining the alignment between current AI capabilities and students'",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Real-Time Localization Framework for Autonomous Basketball Robots",
      "link": "https://arxiv.org/abs/2601.08713",
      "summary": "arXiv:2601.08713v1 Announce Type: cross \nAbstract: Localization is a fundamental capability for autonomous robots, enabling them to operate effectively in dynamic environments. In Robocon 2025, accurate and reliable localization is crucial for improving shooting precision, avoiding collisions with other robots, and navigating the competition field efficiently. In this paper, we propose a hybrid localization algorithm that integrates classical techniques with learning based methods that rely sole",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning",
      "link": "https://arxiv.org/abs/2601.08732",
      "summary": "arXiv:2601.08732v1 Announce Type: cross \nAbstract: Accurate delineation of acute ischemic stroke lesions in MRI is a key component of stroke diagnosis and management. In recent years, deep learning models have been successfully applied to the automatic segmentation of such lesions. While most proposed architectures are based on the U-Net framework, they primarily differ in their choice of loss functions and in the use of deep supervision, residual connections, and attention mechanisms. Moreover,",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback",
      "link": "https://arxiv.org/abs/2601.08734",
      "summary": "arXiv:2601.08734v1 Announce Type: cross \nAbstract: Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-q",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL",
      "link": "https://arxiv.org/abs/2601.08743",
      "summary": "arXiv:2601.08743v1 Announce Type: cross \nAbstract: In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders. To address this",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution",
      "link": "https://arxiv.org/abs/2601.08747",
      "summary": "arXiv:2601.08747v1 Announce Type: cross \nAbstract: Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks.However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "UR-Bench: A Benchmark for Multi-Hop Reasoning over Ultra-High-Resolution Images",
      "link": "https://arxiv.org/abs/2601.08748",
      "summary": "arXiv:2601.08748v1 Announce Type: cross \nAbstract: Recent multimodal large language models (MLLMs) show strong capabilities in visual-language reasoning, yet their performance on ultra-high-resolution imagery remains largely unexplored. Existing visual question answering (VQA) benchmarks typically rely on medium-resolution data, offering limited visual complexity. To bridge this gap, we introduce Ultra-high-resolution Reasoning Benchmark (UR-Bench), a benchmark designed to evaluate the reasoning",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit",
      "link": "https://arxiv.org/abs/2601.08753",
      "summary": "arXiv:2601.08753v1 Announce Type: cross \nAbstract: The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs vary throughout the day. Transit agencies must optim",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs",
      "link": "https://arxiv.org/abs/2601.08773",
      "summary": "arXiv:2601.08773v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation for software engineering often relies on vector similarity search, which captures topical similarity but can fail on multi-hop architectural reasoning such as controller to service to repository chains, interface-driven wiring, and inheritance. This paper benchmarks three retrieval pipelines on Java codebases (Shopizer, with additional runs on ThingsBoard and OpenMRS Core): (A) vector-only No-Graph RAG, (B) an LLM-",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN",
      "link": "https://arxiv.org/abs/2601.08776",
      "summary": "arXiv:2601.08776v1 Announce Type: cross \nAbstract: Histopathology analysis relies on Hematoxylin and Eosin (H&amp;E) staining, but fluorescence microscopy offers complementary information. Converting fluorescence images to H&amp;E-like appearance can aid interpretation and integration with standard workflows. We present a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence microscopy to pseudo H&amp;E stained histopatho",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling",
      "link": "https://arxiv.org/abs/2601.08777",
      "summary": "arXiv:2601.08777v1 Announce Type: cross \nAbstract: Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. We formalize an ideal notion of universal alignment through test-time scaling: for each prompt, the model produces $k\\ge 1$ candidate responses and a user selects their preferred one. We introduce $(k,f(k))$-robust alignment, which requires the $k$-output model to have win rat",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "APEX-SWE",
      "link": "https://arxiv.org/abs/2601.08806",
      "summary": "arXiv:2601.08806v1 Announce Type: cross \nAbstract: We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require constructing end-to-end systems across heterogeneous c",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "S3-CLIP: Video Super Resolution for Person-ReID",
      "link": "https://arxiv.org/abs/2601.08807",
      "summary": "arXiv:2601.08807v1 Announce Type: cross \nAbstract: Tracklet quality is often treated as an afterthought in most person re-identification (ReID) methods, with the majority of research presenting architectural modifications to foundational models. Such approaches neglect an important limitation, posing challenges when deploying ReID systems in real-world, difficult scenarios. In this paper, we introduce S3-CLIP, a video super-resolution-based CLIP-ReID framework developed for the VReID-XFD challen",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge",
      "link": "https://arxiv.org/abs/2601.08808",
      "summary": "arXiv:2601.08808v1 Announce Type: cross \nAbstract: Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single c",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reasoning Matters for 3D Visual Grounding",
      "link": "https://arxiv.org/abs/2601.08811",
      "summary": "arXiv:2601.08811v1 Announce Type: cross \nAbstract: The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains such as mathematics, coding, and scientific discovery. Meanwhile, 3D visual grounding, as a fundamental task in 3D understanding, still remains challenging due to the limited reasoning ability of recent 3D visual grounding models. Most of the current methods incorporate a text encoder and visual feature encoder to generate ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MemRec: Collaborative Memory-Augmented Agentic Recommender System",
      "link": "https://arxiv.org/abs/2601.08816",
      "summary": "arXiv:2601.08816v1 Announce Type: cross \nAbstract: The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurrin",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Motion Attribution for Video Generation",
      "link": "https://arxiv.org/abs/2601.08828",
      "summary": "arXiv:2601.08828v1 Announce Type: cross \nAbstract: Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. We present Motive (MOTIon attribution for Video gEneration), a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. We use this to study which fine-tuning clips improve or degrade temporal dynamics. Motive isolates temporal dynamics from static appearance vi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System",
      "link": "https://arxiv.org/abs/2601.08829",
      "summary": "arXiv:2601.08829v1 Announce Type: cross \nAbstract: In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, includ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Generative Semantic Communication: Diffusion Models Beyond Bit Recovery",
      "link": "https://arxiv.org/abs/2306.04321",
      "summary": "arXiv:2306.04321v2 Announce Type: replace \nAbstract: Semantic communication is expected to be one of the cores of next-generation AI-based communications. One of the possibilities offered by semantic communication is the capability to regenerate, at the destination side, images or videos semantically equivalent to the transmitted ones, without necessarily recovering the transmitted sequence of bits. The current solutions still lack the ability to build complex scenes from the received partial in",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Explaning with trees: interpreting CNNs using hierarchies",
      "link": "https://arxiv.org/abs/2406.13257",
      "summary": "arXiv:2406.13257v2 Announce Type: replace \nAbstract: Challenges persist in providing interpretable explanations for neural network reasoning in explainable AI (xAI). Existing methods like Integrated Gradients produce noisy maps, and LIME, while intuitive, may deviate from the model's reasoning. We introduce a framework that uses hierarchical segmentation techniques for faithful and interpretable explanations of Convolutional Neural Networks (CNNs). Our method constructs model-based hierarchical ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "COSINT-Agent: A Knowledge-Driven Multimodal Agent for Chinese Open Source Intelligence",
      "link": "https://arxiv.org/abs/2503.03215",
      "summary": "arXiv:2503.03215v2 Announce Type: replace \nAbstract: Open Source Intelligence (OSINT) requires the integration and reasoning of diverse multimodal data, presenting significant challenges in deriving actionable insights. Traditional approaches, including multimodal large language models (MLLMs), often struggle to infer complex contextual relationships or deliver comprehensive intelligence from unstructured data sources. In this paper, we introduce COSINT-Agent, a knowledge-driven multimodal agent",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition",
      "link": "https://arxiv.org/abs/2506.07553",
      "summary": "arXiv:2506.07553v3 Announce Type: replace \nAbstract: Optical Chemical Structure Recognition (OCSR) is essential for converting molecular images into machine-readable formats. While recent vision-language models (VLMs) have shown promise, their image-captioning approach often struggles with complex molecular structures and inconsistent annotations. To address these issues, we introduce GTR-VL, featuring two key innovations: (1) the \\textit{Graph Traversal as Visual Chain of Thought} mechanism tha",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "VGC-Bench: Towards Mastering Diverse Team Strategies in Competitive Pok\\'emon",
      "link": "https://arxiv.org/abs/2506.10326",
      "summary": "arXiv:2506.10326v3 Announce Type: replace \nAbstract: Developing AI agents that can robustly adapt to varying strategic landscapes without retraining is a central challenge in multi-agent learning. Pok\\'emon Video Game Championships (VGC) is a domain with a vast space of approximately $10^{139}$ team configurations, far larger than those of other games such as Chess, Go, Poker, StarCraft, or Dota. The combinatorial nature of team building in Pok\\'emon VGC causes optimal strategies to vary substan",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Geometry of Knowledge Allows Extending Diversity Boundaries of Large Language Models",
      "link": "https://arxiv.org/abs/2507.13874",
      "summary": "arXiv:2507.13874v2 Announce Type: replace \nAbstract: Starting from the hypothesis that knowledge in semantic space is organized along structured manifolds, we argue that this geometric structure renders the space explorable. By traversing it and using the resulting continuous representations to condition an LLM's generation distribution, we can systematically expand the model's reachable semantic range. We introduce a framework that requires no modification of LLM parameters and operationalizes ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions",
      "link": "https://arxiv.org/abs/2507.21503",
      "summary": "arXiv:2507.21503v4 Announce Type: replace \nAbstract: Recently Multimodal Large Language Models (MLLMs) have achieved considerable advancements in vision-language tasks, yet produce potentially harmful or untrustworthy content. Despite substantial work investigating the trustworthiness of language models, MMLMs' capability to act honestly, especially when faced with visually unanswerable questions, remains largely underexplored. This work presents the first systematic assessment of honesty behavi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE",
      "link": "https://arxiv.org/abs/2507.21802",
      "summary": "arXiv:2507.21802v3 Announce Type: replace \nAbstract: Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO and DanceGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose $\\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths",
      "link": "https://arxiv.org/abs/2508.08001",
      "summary": "arXiv:2508.08001v3 Announce Type: replace \nAbstract: \"Fedspeak\", the stylized and often nuanced language used by the U.S. Federal Reserve, encodes implicit policy signals and strategic stances. The Federal Open Market Committee strategically employs Fedspeak as a communication tool to shape market expectations and influence both domestic and global economic conditions. As such, automatically parsing and interpreting Fedspeak presents a high-impact challenge, with significant implications for fin",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction",
      "link": "https://arxiv.org/abs/2509.14507",
      "summary": "arXiv:2509.14507v2 Announce Type: replace \nAbstract: Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that simplifies database access for non-technical users by converting natural language queries into SQL commands. Recent advancements, particularly those integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) reasoning, have made significant strides in enhancing NL2SQL performance. However, challenges such as inaccurate task decomposition and keyword ex",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LTL$_f$ Learning Meets Boolean Set Cover",
      "link": "https://arxiv.org/abs/2509.24616",
      "summary": "arXiv:2509.24616v2 Announce Type: replace \nAbstract: Learning formulas in Linear Temporal Logic (LTLf) from finite traces is a fundamental research problem which has found applications in artificial intelligence, software engineering, programming languages, formal methods, control of cyber-physical systems, and robotics. We implement a new CPU tool called Bolt improving over the state of the art by learning formulas more than 100x faster over 70% of the benchmarks, with smaller or equal formulas",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Structured Debate Improves Corporate Credit Reasoning in Financial AI",
      "link": "https://arxiv.org/abs/2510.17108",
      "summary": "arXiv:2510.17108v4 Announce Type: replace \nAbstract: This study investigated LLM-based automation for analyzing non-financial data in corporate credit evaluation. Two systems were developed and compared: a Single-Agent System (SAS), in which one LLM agent infers favorable and adverse repayment signals, and a Popperian Multi-agent Debate System (PMADS), which structures the dual-perspective analysis as adversarial argumentation under the Karl Popper Debate protocol. Evaluation addressed three fro",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Learning \"Partner-Aware\" Collaborators in Multi-Party Collaboration",
      "link": "https://arxiv.org/abs/2510.22462",
      "summary": "arXiv:2510.22462v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are increasingly being deployed in agentic settings where they act as collaborators with humans. Therefore, it is increasingly important to be able to evaluate their abilities to collaborate effectively in multi-turn, multi-party tasks. In this paper, we build on the AI alignment and safe interruptibility literature to offer novel theoretical insights on collaborative behavior between LLM-driven collaborator agents",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ToolRM: Towards Agentic Tool-Use Reward Modeling",
      "link": "https://arxiv.org/abs/2510.26167",
      "summary": "arXiv:2510.26167v2 Announce Type: replace \nAbstract: Reward models (RMs) play a critical role in aligning large language models (LLMs) with human preferences. Yet in the domain of tool learning, the lack of RMs specifically designed for function-calling tasks has limited progress toward more capable agentic AI. We introduce ToolRM, a family of lightweight reward models tailored for general tool-use scenarios. To build these models, we propose a novel pipeline that constructs high-quality pairwis",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control",
      "link": "https://arxiv.org/abs/2511.00551",
      "summary": "arXiv:2511.00551v2 Announce Type: replace \nAbstract: Several studies have employed reinforcement learning (RL) to address the challenges of regional adaptive traffic signal control (ATSC) and achieved promising results. In this field, existing research predominantly adopts multi-agent frameworks. However, the adoption of multi-agent frameworks presents challenges for scalability. Instead, the Traffic signal control (TSC) problem necessitates a single-agent framework. TSC inherently relies on cen",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression",
      "link": "https://arxiv.org/abs/2511.08066",
      "summary": "arXiv:2511.08066v5 Announce Type: replace \nAbstract: Recent years have witnessed the rapid advancements of large language models (LLMs) and their expanding applications, leading to soaring demands for computational resources. The widespread adoption of test-time scaling further intensifies the tension between model capability and resource consumption, highlighting the importance of inference efficiency. However, a unified metric that accurately reflects an LLM's efficiency across diverse model s",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Simulating the Visual World with Artificial Intelligence: A Roadmap",
      "link": "https://arxiv.org/abs/2511.08585",
      "summary": "arXiv:2511.08585v2 Announce Type: replace \nAbstract: The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual generators but also as implicit world models, models that simulate the physical dynamics, agent-environment interactions, and task planning that gov",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Impact of Off-Policy Training Data on Probe Generalisation",
      "link": "https://arxiv.org/abs/2511.17408",
      "summary": "arXiv:2511.17408v3 Announce Type: replace \nAbstract: Probing has emerged as a promising method for monitoring large language models (LLMs), enabling cheap inference-time detection of concerning behaviours. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention pro",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning",
      "link": "https://arxiv.org/abs/2511.21005",
      "summary": "arXiv:2511.21005v5 Announce Type: replace \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preferen",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Sequential Enumeration in Large Language Models",
      "link": "https://arxiv.org/abs/2512.04727",
      "summary": "arXiv:2512.04727v2 Announce Type: replace \nAbstract: Reliably counting and generating sequences of items remain a significant challenge for neural networks, including Large Language Models (LLMs). Indeed, although this capability is readily handled by rule-based symbolic systems based on serial computation, learning to systematically deploy counting procedures is difficult for neural models, which should acquire these skills through learning. Previous research has demonstrated that recurrent arc",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services",
      "link": "https://arxiv.org/abs/2512.07436",
      "summary": "arXiv:2512.07436v2 Announce Type: replace \nAbstract: Recent advances in large reasoning models LRMs have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "TROJail: Trajectory-Level Optimization for Multi-Turn Large Language Model Jailbreaks with Process Rewards",
      "link": "https://arxiv.org/abs/2512.07761",
      "summary": "arXiv:2512.07761v2 Announce Type: replace \nAbstract: Large language models have seen widespread adoption, yet they remain vulnerable to multi-turn jailbreak attacks, threatening their safe deployment. This has led to the task of training automated multi-turn attackers to probe model safety vulnerabilities. However, existing approaches typically rely on turn-level optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate this task as a multi-tu",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance",
      "link": "https://arxiv.org/abs/2512.09114",
      "summary": "arXiv:2512.09114v2 Announce Type: replace \nAbstract: The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case pr",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
      "link": "https://arxiv.org/abs/2512.20387",
      "summary": "arXiv:2512.20387v4 Announce Type: replace \nAbstract: We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SafePro: Evaluating the Safety of Professional-Level AI Agents",
      "link": "https://arxiv.org/abs/2601.06663",
      "summary": "arXiv:2601.06663v2 Announce Type: replace \nAbstract: Large language model-based agents are rapidly evolving from simple conversational assistants into autonomous systems capable of performing complex, professional-level tasks in various domains. While these advancements promise significant productivity gains, they also introduce critical safety risks that remain under-explored. Existing safety evaluations primarily focus on simple, daily assistance tasks, failing to capture the intricate decisio",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Reasoning Models Will Blatantly Lie About Their Reasoning",
      "link": "https://arxiv.org/abs/2601.07663",
      "summary": "arXiv:2601.07663v2 Announce Type: replace \nAbstract: It has been shown that Large Reasoning Models (LRMs) may not *say what they think*: they do not always volunteer information about how certain parts of the input influence their reasoning. But it is one thing for a model to *omit* such information and another, worse thing to *lie* about it. Here, we extend the work of Chen et al. (2025) to show that LRMs will do just this: they will flatly deny relying on hints provided in the prompt in answer",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Cross-Domain Imitation Learning via Optimal Transport",
      "link": "https://arxiv.org/abs/2110.03684",
      "summary": "arXiv:2110.03684v4 Announce Type: replace-cross \nAbstract: Cross-domain imitation learning studies how to leverage expert demonstrations of one agent to train an imitation agent with a different embodiment or morphology. Comparing trajectories and stationary distributions between the expert and imitation agents is challenging because they live on different systems that may not even have the same dimensionality. We propose Gromov-Wasserstein Imitation Learning (GWIL), a method for cross-domain im",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Feed-Forward Optimization With Delayed Feedback for Neural Network Training",
      "link": "https://arxiv.org/abs/2304.13372",
      "summary": "arXiv:2304.13372v2 Announce Type: replace-cross \nAbstract: Backpropagation has long been criticized for being biologically implausible due to its reliance on concepts that are not viable in natural learning processes. Two core issues are the weight transport and update locking problems caused by the forward-backward dependencies, which limit biological plausibility, computational efficiency, and parallelization. Although several alternatives have been proposed to increase biological plausibility",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Explainable Molecular Property Prediction: Aligning Chemical Concepts with Predictions via Language Models",
      "link": "https://arxiv.org/abs/2405.16041",
      "summary": "arXiv:2405.16041v4 Announce Type: replace-cross \nAbstract: Providing explainable molecular property predictions is critical for many scientific domains, such as drug discovery and material science. Though transformer-based language models have shown great potential in accurate molecular property prediction, they neither provide chemically meaningful explanations nor faithfully reveal the molecular structure-property relationships. In this work, we develop a framework for explainable molecular pr",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis",
      "link": "https://arxiv.org/abs/2406.09838",
      "summary": "arXiv:2406.09838v4 Announce Type: replace-cross \nAbstract: Meteorological heatmaps play a vital role in deciphering extreme weather phenomena, yet their inherent complexities marked by irregular contours, unstructured patterns, and complex color variations present unique analytical hurdles for state-of-the-art Vision-Language Models (VLMs). Current state-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks such as precise color identification and spatial localization, result",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Gradient flow in parameter space is equivalent to linear interpolation in output space",
      "link": "https://arxiv.org/abs/2408.01517",
      "summary": "arXiv:2408.01517v3 Announce Type: replace-cross \nAbstract: We prove that the standard gradient flow in parameter space that underlies many training algorithms in deep learning can be continuously deformed into an adapted gradient flow which yields (constrained) Euclidean gradient flow in output space. Moreover, for the $L^{2}$ loss, if the Jacobian of the outputs with respect to the parameters is full rank (for fixed training data), then the time variable can be reparametrized so that the result",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems",
      "link": "https://arxiv.org/abs/2408.15969",
      "summary": "arXiv:2408.15969v3 Announce Type: replace-cross \nAbstract: We examine stability properties of primal-dual gradient flow dynamics for composite convex optimization problems with multiple, possibly nonsmooth, terms in the objective function under the generalized consensus constraint. The proposed dynamics are based on the proximal augmented Lagrangian and they provide a viable alternative to ADMM which faces significant challenges from both analysis and implementation viewpoints in large-scale mul",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Stuffed Mamba: Oversized States Lead to the Inability to Forget",
      "link": "https://arxiv.org/abs/2410.07145",
      "summary": "arXiv:2410.07145v4 Announce Type: replace-cross \nAbstract: Recent advancements in recurrent architectures, such as Mamba and RWKV, have showcased strong language capabilities. Unlike transformer-based models, these architectures encode all contextual information into a fixed-size state, leading to great inference efficiency. However, this approach can cause information interference, where different token data conflicts, resulting in performance degradation and incoherent outputs beyond a certain",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Beyond Backpropagation: Optimization with Multi-Tangent Forward Gradients",
      "link": "https://arxiv.org/abs/2410.17764",
      "summary": "arXiv:2410.17764v2 Announce Type: replace-cross \nAbstract: The gradients used to train neural networks are typically computed using backpropagation. While an efficient way to obtain exact gradients, backpropagation is computationally expensive, hinders parallelization, and is biologically implausible. Forward gradients are an approach to approximate the gradients from directional derivatives along random tangents computed by forward-mode automatic differentiation. So far, research has focused on",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "CausAdv: A Causal-based Framework for Detecting Adversarial Examples",
      "link": "https://arxiv.org/abs/2411.00839",
      "summary": "arXiv:2411.00839v2 Announce Type: replace-cross \nAbstract: Deep learning has led to tremendous success in computer vision, largely due to Convolutional Neural Networks (CNNs). However, CNNs have been shown to be vulnerable to crafted adversarial perturbations. This vulnerability of adversarial examples has has motivated research into improving model robustness through adversarial detection and defense methods. In this paper, we address the adversarial robustness of CNNs through causal reasoning.",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning",
      "link": "https://arxiv.org/abs/2412.04948",
      "summary": "arXiv:2412.04948v2 Announce Type: replace-cross \nAbstract: Autoregressive large language models (LLMs) pre-trained by next token prediction are inherently proficient in generative tasks. However, their performance on knowledge-driven tasks such as factual knowledge querying remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured knowledge bases, can provide reliable knowledge for LLMs, potentially compensating for their knowledge deficiencies. Aligning LLMs with explicit, stru",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions",
      "link": "https://arxiv.org/abs/2502.00568",
      "summary": "arXiv:2502.00568v4 Announce Type: replace-cross \nAbstract: Emerging research has highlighted that artificial intelligence-based multimodal fusion of digital pathology and transcriptomic features can improve cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction. However, such direct fusion is impractical in clinical settings, where histopathology remains the gold standard and transcriptomic tests are rarely requested in public healthcare. We experiment on two publicly avai",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "How Memory in Optimization Algorithms Implicitly Modifies the Loss",
      "link": "https://arxiv.org/abs/2502.02132",
      "summary": "arXiv:2502.02132v3 Announce Type: replace-cross \nAbstract: In modern optimization methods used in deep learning, each update depends on the history of previous iterations, often referred to as memory, and this dependence decays fast as the iterates go further into the past. For example, gradient descent with momentum has exponentially decaying memory through exponentially averaged past gradients. We introduce a general technique for identifying a memoryless algorithm that approximates an optimiz",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection",
      "link": "https://arxiv.org/abs/2502.12119",
      "summary": "arXiv:2502.12119v3 Announce Type: replace-cross \nAbstract: Visual instruction tuning adapts pre-trained Multimodal Large Language Models (MLLMs) to follow human instructions for real-world applications. However, the rapid growth of these datasets introduces significant redundancy, leading to increased computational costs. Existing methods for selecting instruction data aim to prune this redundancy, but predominantly rely on computationally demanding techniques such as proxy-based inference or tr",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Provocations from the Humanities for Generative AI Research",
      "link": "https://arxiv.org/abs/2502.19190",
      "summary": "arXiv:2502.19190v2 Announce Type: replace-cross \nAbstract: The effects of generative AI are experienced by a broad range of constituencies, but the disciplinary inputs to its development have been surprisingly narrow. Here we present a set of provocations from humanities researchers -- currently underrepresented in AI development -- intended to inform its future applications and enrich ongoing conversations about its uses, impact, and harms. Drawing from relevant humanities scholarship, along wi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge",
      "link": "https://arxiv.org/abs/2503.04971",
      "summary": "arXiv:2503.04971v2 Announce Type: replace-cross \nAbstract: Foundation models (FMs) such as GPT-4 exhibit exceptional generative capabilities across diverse downstream tasks through fine-tuning. Split Federated Learning (SFL) facilitates privacy-preserving FM fine-tuning on resource-constrained local devices by offloading partial FM computations to edge servers, enabling device-edge synergistic fine-tuning. Practical edge networks often host multiple SFL tenants to support diversified downstream ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Using Subgraph GNNs for Node Classification:an Overlooked Potential Approach",
      "link": "https://arxiv.org/abs/2503.06614",
      "summary": "arXiv:2503.06614v2 Announce Type: replace-cross \nAbstract: Previous studies have demonstrated the strong performance of Graph Neural Networks (GNNs) in node classification. However, most existing GNNs adopt a node-centric perspective and rely on global message passing, leading to high computational and memory costs that hinder scalability. To mitigate these challenges, subgraph-based methods have been introduced, leveraging local subgraphs as approximations of full computational trees. While thi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "UniF$^2$ace: A Unified Fine-grained Face Understanding and Generation Model",
      "link": "https://arxiv.org/abs/2503.08120",
      "summary": "arXiv:2503.08120v5 Announce Type: replace-cross \nAbstract: Unified multimodal models (UMMs) have emerged as a powerful paradigm in fundamental cross-modality research, demonstrating significant potential in both image understanding and generation. However, existing research in the face domain primarily faces two challenges: $\\textbf{(1)}$ $\\textbf{fragmentation development}$, with existing methods failing to unify understanding and generation into a single one, hindering the way to artificial ge",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Kolmogorov--Arnold stability",
      "link": "https://arxiv.org/abs/2504.05255",
      "summary": "arXiv:2504.05255v3 Announce Type: replace-cross \nAbstract: Regarding the representation theorem of Kolmogorov and Arnold (KA) as an algorithm for representing or <> functions, we test its robustness by analyzing its stability to withstand re-parameterizations of the hidden space. One may think of such re-parameterizations as the work of an adversary attempting to foil the construction of the KA outer function. We find KA to be stable under countable collections of continuous re-parameterizations",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Hallucination, reliability, and the role of generative AI in science",
      "link": "https://arxiv.org/abs/2504.08526",
      "summary": "arXiv:2504.08526v2 Announce Type: replace-cross \nAbstract: Generative AI increasingly supports scientific inference, from protein structure prediction to weather forecasting. Yet its distinctive failure mode, hallucination, raises epistemic alarm bells. I argue that this failure mode can be addressed by shifting from data-centric to phenomenon-centric assessment. Through case studies of AlphaFold and GenCast, I show how scientific workflows discipline generative models through theory-guided trai",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers",
      "link": "https://arxiv.org/abs/2504.08999",
      "summary": "arXiv:2504.08999v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) are increasingly augmented with external tools through standardized interfaces like the Model Context Protocol (MCP). However, current MCP implementations face critical limitations: they typically require local process execution through STDIO transports, making them impractical for resource-constrained environments like mobile devices, web browsers, and edge computing. We present MCP Bridge, a lightweight RES",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation",
      "link": "https://arxiv.org/abs/2505.07917",
      "summary": "arXiv:2505.07917v2 Announce Type: replace-cross \nAbstract: Biomedical question-answering (QA) systems require effective retrieval and generation components to ensure accuracy, efficiency, and scalability. This study systematically examines a Retrieval-Augmented Generation (RAG) system for biomedical QA, evaluating retrieval strategies and response time trade-offs. We first assess state-of-the-art retrieval methods, including BM25, BioBERT, MedCPT, and a hybrid approach, alongside common data sto",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases",
      "link": "https://arxiv.org/abs/2505.09246",
      "summary": "arXiv:2505.09246v2 Announce Type: replace-cross \nAbstract: In many real-world settings, machine learning models and interactive systems have access to both structured knowledge, e.g., knowledge graphs or tables, and unstructured content, e.g., natural language documents. However, most rely on either. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking unstructured content to nodes within structured data, thereby enabling new strategies for knowledge access and use. In this work, we",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks",
      "link": "https://arxiv.org/abs/2505.13565",
      "summary": "arXiv:2505.13565v2 Announce Type: replace-cross \nAbstract: Artificial Intelligence (AI) poses both significant risks and valuable opportunities for democratic governance. This paper introduces a dual taxonomy to evaluate AI's complex relationship with democracy: the AI Risks to Democracy (AIRD) taxonomy, which identifies how AI can undermine core democratic principles such as autonomy, fairness, and trust; and the AI's Positive Contributions to Democracy (AIPD) taxonomy, which highlights AI's po",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Bruno: Backpropagation Running Undersampled for Novel device Optimization",
      "link": "https://arxiv.org/abs/2505.17791",
      "summary": "arXiv:2505.17791v2 Announce Type: replace-cross \nAbstract: Recent efforts to improve the efficiency of neuromorphic and machine learning systems have centred on developing of specialised hardware for neural networks. These systems typically feature architectures that go beyond the von Neumann model employed in general-purpose hardware such as GPUs, offering potential efficiency and performance gains. However, neural networks developed for specialised hardware must consider its specific character",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality",
      "link": "https://arxiv.org/abs/2505.18227",
      "summary": "arXiv:2505.18227v3 Announce Type: replace-cross \nAbstract: In Transformer architectures, tokens\\textemdash discrete units derived from raw data\\textemdash are formed by segmenting inputs into fixed-length chunks. Each token is then mapped to an embedding, enabling parallel attention computations while preserving the input's essential information. Due to the quadratic computational complexity of transformer self-attention mechanisms, token reduction has primarily been used as an efficiency strate",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL",
      "link": "https://arxiv.org/abs/2505.20315",
      "summary": "arXiv:2505.20315v2 Announce Type: replace-cross \nAbstract: Translating natural language into SQL (Test2SQL) is a longstanding challenge at the intersection of natural language understanding and structured data access. While large language models (LLMs) have significantly improved fluency in SQL generation, producing correct and executable SQL--particularly for complex queries--remains a bottleneck. We present Arctic-Text2SQL-R1, a reinforcement learning (RL) framework and model family designed t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Differential Perspective on Distributional Reinforcement Learning",
      "link": "https://arxiv.org/abs/2506.03333",
      "summary": "arXiv:2506.03333v2 Announce Type: replace-cross \nAbstract: To date, distributional reinforcement learning (distributional RL) methods have exclusively focused on the discounted setting, where an agent aims to optimize a discounted sum of rewards over time. In this work, we extend distributional RL to the average-reward setting, where an agent aims to optimize the reward received per time step. In particular, we utilize a quantile-based approach to develop the first set of algorithms that can suc",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation",
      "link": "https://arxiv.org/abs/2506.05952",
      "summary": "arXiv:2506.05952v3 Announce Type: replace-cross \nAbstract: Recent advances in transformer-based text-to-motion generation have led to impressive progress in synthesizing high-quality human motion. Nevertheless, jointly achieving high fidelity, streaming capability, real-time responsiveness, and scalability remains a fundamental challenge. In this paper, we propose MOGO (Motion Generation with One-pass), a novel autoregressive framework tailored for efficient and real-time 3D motion generation. M",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning",
      "link": "https://arxiv.org/abs/2506.09644",
      "summary": "arXiv:2506.09644v2 Announce Type: replace-cross \nAbstract: Autoencoders empower state-of-the-art image and video generative models by compressing pixels into a latent space through visual tokenization. Although recent advances have alleviated the performance degradation of autoencoders under high compression ratios, addressing the training instability caused by GAN remains an open challenge. While improving spatial compression, we also aim to minimize the latent space dimensionality, enabling mo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training",
      "link": "https://arxiv.org/abs/2506.10035",
      "summary": "arXiv:2506.10035v3 Announce Type: replace-cross \nAbstract: Recent advancements in text-to-image (T2I) generation have led to the emergence of highly expressive models such as diffusion transformers (DiTs), exemplified by FLUX. However, their massive parameter sizes lead to slow inference, high memory usage, and poor deployability. Existing acceleration methods (e.g., single-step distillation and attention pruning) often suffer from significant performance degradation and incur substantial traini",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Semi-Tensor-Product Based Convolutional Neural Networks",
      "link": "https://arxiv.org/abs/2506.10407",
      "summary": "arXiv:2506.10407v2 Announce Type: replace-cross \nAbstract: The semi-tensor product of vectors generalizes the conventional inner product, enabling algebraic operations between vectors of different dimensions. Building upon this foundation, we introduce a domain-based convolutional product and integrate it with the STP to formulate a padding-free convolutional operation. This new operation inherently avoids zero or other artificial padding, thereby eliminating redundant information and boundary a",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Data Science: a Natural Ecosystem",
      "link": "https://arxiv.org/abs/2506.11010",
      "summary": "arXiv:2506.11010v2 Announce Type: replace-cross \nAbstract: This manuscript provides a systemic and data-centric view of what we term essential data science, as a natural ecosystem with challenges and missions stemming from the fusion of data universe with its multiple combinations of the 5D complexities (data structure, domain, cardinality, causality, and ethics) with the phases of the data life cycle. Data agents perform tasks driven by specific goals. The data scientist is an abstract entity t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Regression-adjusted Monte Carlo Estimators for Shapley Values and Probabilistic Values",
      "link": "https://arxiv.org/abs/2506.11849",
      "summary": "arXiv:2506.11849v2 Announce Type: replace-cross \nAbstract: With origins in game theory, probabilistic values like Shapley values, Banzhaf values, and semi-values have emerged as a central tool in explainable AI. They are used for feature attribution, data attribution, data valuation, and more. Since all of these values require exponential time to compute exactly, research has focused on efficient approximation methods using two techniques: Monte Carlo sampling and linear regression formulations.",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control",
      "link": "https://arxiv.org/abs/2506.20993",
      "summary": "arXiv:2506.20993v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) have gained significant traction across a wide range of fields in recent years. There is also a growing expectation for them to display human-like personalities during interactions. To meet this expectation, numerous studies have proposed methods for modelling LLM personalities through psychometric evaluations. However, most existing models face two major limitations: they rely on the Big Five (OCEAN) framewo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Quantization-Aware Neuromorphic Architecture for Skin Disease Classification on Resource-Constrained Devices",
      "link": "https://arxiv.org/abs/2507.15958",
      "summary": "arXiv:2507.15958v3 Announce Type: replace-cross \nAbstract: On-device skin lesion analysis is constrained by the compute and energy cost of conventional CNN inference and by the need to update models as new patient data become available. We propose QANA, a quantization-aware CNN backbone embedded in an end-to-end pipeline engineered for conversion-stable neuromorphic execution. QANA replaces conversion-fragile components with spike-compatible transformations by bounding intermediate activations a",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis",
      "link": "https://arxiv.org/abs/2507.16641",
      "summary": "arXiv:2507.16641v2 Announce Type: replace-cross \nAbstract: A reinforcement learning (RL) framework is introduced for the efficient synthesis of quantum circuits that generate specified target quantum states from a fixed initial state, addressing a central challenge in both the Noisy Intermediate-Scale Quantum (NISQ) era and future fault-tolerant quantum computing. The approach utilizes tabular Q-learning, based on action sequences, within a discretized quantum state space, to effectively manage ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "EvoC2Rust: A Skeleton-guided Framework for Project-Level C-to-Rust Translation",
      "link": "https://arxiv.org/abs/2508.04295",
      "summary": "arXiv:2508.04295v4 Announce Type: replace-cross \nAbstract: Translating legacy C codebases to Rust is increasingly demanded for building safety-critical systems. While various approaches have emerged for this task, they face inherent trade-offs: rule-based methods often struggle to satisfy code safety and idiomaticity requirements, while LLM-based methods frequently fail to generate semantically equivalent Rust code, due to the heavy dependencies of modules across the entire codebase. Recent stud",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots",
      "link": "https://arxiv.org/abs/2508.06538",
      "summary": "arXiv:2508.06538v2 Announce Type: replace-cross \nAbstract: Reduced-order models are central to motion planning and control of quadruped robots, yet existing templates are often hand-crafted for a specific locomotion modality. This motivates the need for automatic methods that extract task-specific, interpretable low-dimensional dynamics directly from data. We propose a methodology that combines a linear autoencoder with symbolic regression to derive such models. The linear autoencoder provides a",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Vocabulary Expansion of Large Language Models via Kullback-Leibler-Based Self-Distillation",
      "link": "https://arxiv.org/abs/2508.15807",
      "summary": "arXiv:2508.15807v2 Announce Type: replace-cross \nAbstract: Large pre-trained language models often struggle to incorporate new domain-specific terminology when fine-tuned on small, specialized corpora. In this work, we address the challenge of vocabulary expansion in frozen LLMs by introducing a mathematically grounded method for knowledge distillation via KL divergence, even when the original and extended models use different tokenizations. This allows the student model to inherit distributiona",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Evolution of Thought: Tracking LLM Overthinking via Reasoning Dynamics Analysis",
      "link": "https://arxiv.org/abs/2508.17627",
      "summary": "arXiv:2508.17627v2 Announce Type: replace-cross \nAbstract: Test-time scaling via explicit reasoning trajectories significantly boosts large language model (LLM) performance but often triggers overthinking. To explore this, we analyze reasoning through two lenses: Reasoning Length Dynamics, which reveals a compensatory trade-off between thinking and answer content length that eventually leads to thinking redundancy, and Reasoning Semantic Dynamics, which identifies semantic convergence and repeti",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "SLogic: Subgraph-Informed Logical Rule Learning for Knowledge Graph Completion",
      "link": "https://arxiv.org/abs/2510.00279",
      "summary": "arXiv:2510.00279v2 Announce Type: replace-cross \nAbstract: Logical rule-based methods offer an interpretable approach to knowledge graph completion (KGC) by capturing compositional relationships in the form of human-readable inference rules. While existing logical rule-based methods learn rule confidence scores, they typically assign a global weight to each rule schema, applied uniformly across the graph. This is a significant limitation, as a rule's importance often varies depending on the spec",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Human Mobility Datasets Enriched With Contextual and Social Dimensions",
      "link": "https://arxiv.org/abs/2510.02333",
      "summary": "arXiv:2510.02333v3 Announce Type: replace-cross \nAbstract: In this resource paper, we present two publicly available datasets of semantically enriched human trajectories, together with the pipeline to build them. The trajectories are publicly available GPS traces retrieved from OpenStreetMap. Each dataset includes contextual layers such as stops, moves, points of interest (POIs), inferred transportation modes, and weather data. A novel semantic feature is the inclusion of synthetic, realistic so",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AutoContext: Instance-Level Context Learning for LLM Agents",
      "link": "https://arxiv.org/abs/2510.02369",
      "summary": "arXiv:2510.02369v3 Announce Type: replace-cross \nAbstract: Current LLM agents typically lack instance-level context, which comprises concrete facts such as environment structure, system configurations, and local mechanics. Consequently, existing methods are forced to intertwine exploration with task execution. This coupling leads to redundant interactions and fragile decision-making, as agents must repeatedly rediscover the same information for every new task. To address this, we introduce AutoC",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Foundations of LLM Knowledge Materialization: Termination, Reproducibility, Robustness",
      "link": "https://arxiv.org/abs/2510.06780",
      "summary": "arXiv:2510.06780v3 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) encode substantial factual knowledge, yet measuring and systematizing this knowledge remains challenging. Converting it into structured format, for example through recursive extraction approaches such as the GPTKB methodology (Hu et al., 2025b), is still underexplored. Key open questions include whether such extraction can terminate, whether its outputs are reproducible, and how robust they are to variations.",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Are My Optimized Prompts Compromised? Exploring Vulnerabilities of LLM-based Optimizers",
      "link": "https://arxiv.org/abs/2510.14381",
      "summary": "arXiv:2510.14381v2 Announce Type: replace-cross \nAbstract: Large language model (LLM) systems increasingly power everyday AI applications such as chatbots, computer-use assistants, and autonomous robots, where performance often depends on manually well-crafted prompts. LLM-based prompt optimizers reduce that effort by iteratively refining prompts from scored feedback, yet the security of this optimization stage remains underexamined. We present the first systematic analysis of poisoning risks in",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following",
      "link": "https://arxiv.org/abs/2510.14420",
      "summary": "arXiv:2510.14420v3 Announce Type: replace-cross \nAbstract: Language models often struggle to follow multi-constraint instructions that are crucial for real-world applications. Existing reinforcement learning (RL) approaches suffer from dependency on external supervision and sparse reward signals from multi-constraint tasks. We propose a label-free self-supervised RL framework that eliminates dependency on external supervision by deriving reward signals directly from instructions and generating p",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "WaveNet's Precision in EEG Classification",
      "link": "https://arxiv.org/abs/2510.15947",
      "summary": "arXiv:2510.15947v2 Announce Type: replace-cross \nAbstract: This study introduces a WaveNet-based deep learning model designed to automate the classification of intracranial electroencephalography (iEEG) signals into physiological activity, pathological (epileptic) activity, power-line noise, and other non-cerebral artifacts. Traditional methods for iEEG signal classification, which rely on expert visual review, are becoming increasingly impractical due to the growing complexity and volume of iEE",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Asymptotically Stable Quaternion-valued Hopfield-structured Neural Network with Periodic Projection-based Supervised Learning Rules",
      "link": "https://arxiv.org/abs/2510.16607",
      "summary": "arXiv:2510.16607v2 Announce Type: replace-cross \nAbstract: Motivated by the geometric advantages of quaternions in representing rotations and postures, we propose a quaternion-valued supervised learning Hopfield-structured neural network (QSHNN) with a fully connected structure inspired by the classic Hopfield neural network (HNN). Starting from a continuous-time dynamical model of HNNs, we extend the formulation to the quaternionic domain and establish the existence and uniqueness of fixed poin",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "On the Sample Complexity of Differentially Private Policy Optimization",
      "link": "https://arxiv.org/abs/2510.21060",
      "summary": "arXiv:2510.21060v2 Announce Type: replace-cross \nAbstract: Policy optimization (PO) is a cornerstone of modern reinforcement learning (RL), with diverse applications spanning robotics, healthcare, and large language model training. The increasing deployment of PO in sensitive domains, however, raises significant privacy concerns. In this paper, we initiate a theoretical study of differentially private policy optimization, focusing explicitly on its sample complexity. We first formalize an approp",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents",
      "link": "https://arxiv.org/abs/2510.23675",
      "summary": "arXiv:2510.23675v2 Announce Type: replace-cross \nAbstract: Modern coding agents integrated into IDEs orchestrate powerful tools and high-privilege system access, creating a high-stakes attack surface. Prior work on Indirect Prompt Injection (IPI) is mainly query-specific, requiring particular user queries as triggers and leading to poor generalizability. We propose query-agnostic IPI, a new attack paradigm that reliably executes malicious payloads under arbitrary user queries. Our key insight is",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "LLM generation novelty through the lens of semantic similarity",
      "link": "https://arxiv.org/abs/2510.27313",
      "summary": "arXiv:2510.27313v2 Announce Type: replace-cross \nAbstract: Generation novelty is a key indicator of an LLM's ability to generalize, yet measuring it against full pretraining corpora is computationally challenging. Existing evaluations often rely on lexical overlap, failing to detect paraphrased text, or do not consider the full pretraining corpus. We frame novelty as a semantic retrieval problem. This framing enables us to address novelty with modern embedding and indexing pipelines, allowing fo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Quantum Machine Unlearning: Foundations, Mechanisms, and Taxonomy",
      "link": "https://arxiv.org/abs/2511.00406",
      "summary": "arXiv:2511.00406v2 Announce Type: replace-cross \nAbstract: Quantum Machine Unlearning has emerged as a foundational challenge at the intersection of quantum information theory privacypreserving computation and trustworthy artificial intelligence This paper advances QMU by establishing a formal framework that unifies physical constraints algorithmic mechanisms and ethical governance within a verifiable paradigm We define forgetting as a contraction of distinguishability between pre and postunlear",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations",
      "link": "https://arxiv.org/abs/2511.00549",
      "summary": "arXiv:2511.00549v2 Announce Type: replace-cross \nAbstract: Traffic congestion, primarily driven by intersection queuing, significantly impacts urban living standards, safety, environmental quality, and economic efficiency. While Traffic Signal Control (TSC) systems hold potential for congestion mitigation, traditional optimization models often fail to capture real-world traffic complexity and dynamics. This study introduces a novel single-agent reinforcement learning (RL) framework for regional ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Multi-Personality Generation of LLMs at Decoding-time",
      "link": "https://arxiv.org/abs/2511.01891",
      "summary": "arXiv:2511.01891v3 Announce Type: replace-cross \nAbstract: Multi-personality generation for LLMs, enabling simultaneous embodiment of multiple personalization attributes, is a fundamental challenge. Existing retraining-based approaches are costly and poorly scalable, while decoding-time methods often rely on external models or heuristics, limiting flexibility and robustness. In this paper, we propose a novel Multi-Personality Generation (MPG) framework under the decoding-time combination paradig",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment",
      "link": "https://arxiv.org/abs/2511.08399",
      "summary": "arXiv:2511.08399v2 Announce Type: replace-cross \nAbstract: Most multimodal models treat every negative pair alike, ignoring the ambiguous negatives that differ from the positive by only a small detail. We propose Boundary-Aware Curriculum with Local Attention (BACL), a lightweight add-on that turns these borderline cases into a curriculum signal. A Boundary-aware Negative Sampler gradually raises difficulty, while a Contrastive Local Attention loss highlights where the mismatch occurs. The two m",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PINGS-X: Physics-Informed Normalized Gaussian Splatting with Axes Alignment for Efficient Super-Resolution of 4D Flow MRI",
      "link": "https://arxiv.org/abs/2511.11048",
      "summary": "arXiv:2511.11048v2 Announce Type: replace-cross \nAbstract: 4D flow magnetic resonance imaging (MRI) is a reliable, non-invasive approach for estimating blood flow velocities, vital for cardiovascular diagnostics. Unlike conventional MRI focused on anatomical structures, 4D flow MRI requires high spatiotemporal resolution for early detection of critical conditions such as stenosis or aneurysms. However, achieving such resolution typically results in prolonged scan times, creating a trade-off betw",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "On the Entropy Calibration of Language Models",
      "link": "https://arxiv.org/abs/2511.11966",
      "summary": "arXiv:2511.11966v2 Announce Type: replace-cross \nAbstract: We study the problem of entropy calibration, which asks whether a language model's entropy over generations matches its log loss on human text. Past work found that models are miscalibrated, with entropy per step increasing as generations grow longer, due to error accumulation. To calibrate the model and improve text quality, it has become standard practice to truncate the distribution, but this approach reduces output diversity, which w",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function",
      "link": "https://arxiv.org/abs/2512.04559",
      "summary": "arXiv:2512.04559v2 Announce Type: replace-cross \nAbstract: Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose Soft Q-based Diffusion Finetuning (SQDF), a novel KL-regularized RL method for diffusion alignment that appli",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability",
      "link": "https://arxiv.org/abs/2512.05534",
      "summary": "arXiv:2512.05534v2 Announce Type: replace-cross \nAbstract: As AI models achieve remarkable capabilities across diverse domains, understanding what representations they learn and how they process information has become increasingly important for both scientific progress and trustworthy deployment. Recent works in mechanistic interpretability have shown that neural networks represent meaningful concepts as directions in their representation spaces and often encode diverse concepts in superposition",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Functional Percolation: Criticality of Form and Function",
      "link": "https://arxiv.org/abs/2512.09317",
      "summary": "arXiv:2512.09317v4 Announce Type: replace-cross \nAbstract: Understanding how network structure constrains and enables information processing is a central problem in the statistical mechanics of interacting systems. Here we study random networks across the structural percolation transition and analyze how connectivity governs realizable input-output transformations under cascade dynamics. Using Erdos-Renyi networks as a minimal ensemble, we examine structural, functional, and information-theoreti",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity",
      "link": "https://arxiv.org/abs/2512.12688",
      "summary": "arXiv:2512.12688v2 Announce Type: replace-cross \nAbstract: Prompts can switch a model's behavior even when the weights are fixed, yet this phenomenon is rarely treated as a clean theoretical object rather than a heuristic. We study the family of functions obtainable by holding a Transformer backbone fixed as an executor and varying only the prompt. Our core idea is to view the prompt as an externally injected program and to construct a simplified Transformer that interprets it to implement diffe",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Memory in the Age of AI Agents",
      "link": "https://arxiv.org/abs/2512.13564",
      "summary": "arXiv:2512.13564v2 Announce Type: replace-cross \nAbstract: Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory termi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics",
      "link": "https://arxiv.org/abs/2512.18209",
      "summary": "arXiv:2512.18209v5 Announce Type: replace-cross \nAbstract: Empirical power--law scaling has been widely observed across modern deep learning systems, yet its theoretical origins and scope of validity remain incompletely understood. The Generalized Resolution--Shell Dynamics (GRSD) framework models learning as spectral energy transport across logarithmic resolution shells, providing a coarse--grained dynamical description of training. Within GRSD, power--law scaling corresponds to a particularly ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PathoSyn: Imaging-Pathology MRI Synthesis via Disentangled Deviation Diffusion",
      "link": "https://arxiv.org/abs/2512.23130",
      "summary": "arXiv:2512.23130v2 Announce Type: replace-cross \nAbstract: We present PathoSyn, a unified generative framework for Magnetic Resonance Imaging (MRI) image synthesis that reformulates imaging-pathology as a disentangled additive deviation on a stable anatomical manifold. Current generative models typically operate in the global pixel domain or rely on binary masks, these paradigms often suffer from feature entanglement, leading to corrupted anatomical substrates or structural discontinuities. Path",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "AgenticTCAD: A LLM-based Multi-Agent Framework for Automated TCAD Code Generation and Device Optimization",
      "link": "https://arxiv.org/abs/2512.23742",
      "summary": "arXiv:2512.23742v2 Announce Type: replace-cross \nAbstract: With the continued scaling of advanced technology nodes, the design-technology co-optimization (DTCO) paradigm has become increasingly critical, rendering efficient device design and optimization essential. In the domain of TCAD simulation, however, the scarcity of open-source resources hinders language models from generating valid TCAD code. To overcome this limitation, we construct an open-source TCAD dataset curated by experts and fin",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Modeling Language as a Sequence of Thoughts",
      "link": "https://arxiv.org/abs/2512.25026",
      "summary": "arXiv:2512.25026v2 Announce Type: replace-cross \nAbstract: Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens, but by relying primarily on surface-level co-occurrence statistics they fail to form globally consistent latent representations of entities and events, which contributes to poor relational generalization (the reversal curse), contextualization errors, and data inefficiency. Cognitive science, by contrast, shows that human compre",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Permission Manifests for Web Agents",
      "link": "https://arxiv.org/abs/2601.02371",
      "summary": "arXiv:2601.02371v2 Announce Type: replace-cross \nAbstract: The rise of Large Language Model (LLM)-based web agents represents a significant shift in automated interactions with the web. Unlike traditional crawlers that follow simple conventions, such as robots$.$txt, modern agents engage with websites in sophisticated ways: navigating complex interfaces, extracting structured information, and completing end-to-end tasks. Existing governance mechanisms were not designed for these capabilities. Wi",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Decentralized Autoregressive Generation",
      "link": "https://arxiv.org/abs/2601.03184",
      "summary": "arXiv:2601.03184v2 Announce Type: replace-cross \nAbstract: We present a theoretical analysis of decentralization of autoregressive generation. We define the Decentralized Discrete Flow Matching objective, by expressing probability generating velocity as a linear combination of expert flows. We also conduct experiments demonstrating the equivalence between decentralized and centralized training settings for multimodal language models across diverse set of benchmarks. Specifically, we compare two ",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning",
      "link": "https://arxiv.org/abs/2601.03910",
      "summary": "arXiv:2601.03910v2 Announce Type: replace-cross \nAbstract: Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since foun",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Apollo: Unified Multi-Task Audio-Video Joint Generation",
      "link": "https://arxiv.org/abs/2601.04151",
      "summary": "arXiv:2601.04151v2 Announce Type: replace-cross \nAbstract: Audio-video joint generation has progressed rapidly, yet substantial challenges still remain. Non-commercial approaches still suffer audio-visual asynchrony, poor lip-speech alignment, and unimodal degradation, which can be stemmed from weak audio-visual correspondence modeling, limited generalization, and scarce high-quality dense-caption data. To address these issues, we introduce Apollo and delve into three axes--model architecture, t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "A Vision for Multisensory Intelligence: Sensing, Science, and Synergy",
      "link": "https://arxiv.org/abs/2601.04563",
      "summary": "arXiv:2601.04563v3 Announce Type: replace-cross \nAbstract: Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI t",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following",
      "link": "https://arxiv.org/abs/2601.04954",
      "summary": "arXiv:2601.04954v2 Announce Type: replace-cross \nAbstract: A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperfor",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "STELP: Secure Transpilation and Execution of LLM-Generated Programs",
      "link": "https://arxiv.org/abs/2601.05467",
      "summary": "arXiv:2601.05467v2 Announce Type: replace-cross \nAbstract: Rapid evolution of Large Language Models (LLMs) has achieved major advances in reasoning, planning, and function-calling capabilities. Multi-agentic collaborative frameworks using such LLMs place them at the center of solving software development-related tasks such as code generation. However, direct use of LLM generated code in production software development systems is problematic. The code could be unstable or erroneous and contain vu",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning",
      "link": "https://arxiv.org/abs/2601.06002",
      "summary": "arXiv:2601.06002v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like)",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Data Work in Egypt: Who Are the Workers Behind Artificial Intelligence?",
      "link": "https://arxiv.org/abs/2601.06057",
      "summary": "arXiv:2601.06057v2 Announce Type: replace-cross \nAbstract: The report highlights the role of Egyptian data workers in the global value chains of Artificial Intelligence (AI). These workers generate and annotate data for machine learning, check outputs, and they connect with overseas AI producers via international digital labor platforms, where they perform on-demand tasks and are typically paid by piecework, with no long-term commitment. Most of these workers are young, highly educated men, with",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "GenAITEd Ghana: A First-of-Its-Kind Context-Aware and Curriculum-Aligned Conversational AI Agent for Teacher Education",
      "link": "https://arxiv.org/abs/2601.06093",
      "summary": "arXiv:2601.06093v2 Announce Type: replace-cross \nAbstract: Global frameworks increasingly advocate for Responsible Artificial Intelligence (AI) in education, yet they provide limited guidance on how ethical, culturally responsive, and curriculum-aligned AI can be operationalized within functioning teacher education systems, particularly in the Global South. This study addresses this gap through the design and evaluation of GenAITEd Ghana, a context-aware, region-specific conversational AI protot",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "When Smaller Wins: Dual-Stage Distillation and Pareto-Guided Compression of Liquid Neural Networks for Edge Battery Prognostics",
      "link": "https://arxiv.org/abs/2601.06227",
      "summary": "arXiv:2601.06227v2 Announce Type: replace-cross \nAbstract: Battery management systems increasingly require accurate battery health prognostics under strict on-device constraints. This paper presents DLNet, a practical framework with dual-stage distillation of liquid neural networks that turns a high-capacity model into compact and edge-deployable models for battery health prediction. DLNet first applies Euler discretization to reformulate liquid dynamics for embedded compatibility. It then perfo",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences",
      "link": "https://arxiv.org/abs/2601.06789",
      "summary": "arXiv:2601.06789v2 Announce Type: replace-cross \nAbstract: While autonomous software engineering (SWE) agents are reshaping programming paradigms, they currently suffer from a \"closed-world\" limitation: they attempt to fix bugs from scratch or solely using local context, ignoring the immense historical human experience available on platforms like GitHub. Accessing this open-world experience is hindered by the unstructured and fragmented nature of real-world issue-tracking data. In this paper, we",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Measuring Iterative Temporal Reasoning with Time Puzzles",
      "link": "https://arxiv.org/abs/2601.07148",
      "summary": "arXiv:2601.07148v2 Announce Type: replace-cross \nAbstract: We introduce Time Puzzles, a constraint-based date inference task for evaluating iterative temporal reasoning. Each puzzle combines factual temporal anchors with (cross-cultural) calendar relations, admits one or multiple valid solution dates, and is algorithmically generated for controlled, dynamic, and continual evaluation. Across 13 diverse LLMs, Time Puzzles well distinguishes their iterative temporal reasoning capabilities and remai",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "PRPO: Aligning Process Reward with Outcome Reward in Policy Optimization",
      "link": "https://arxiv.org/abs/2601.07182",
      "summary": "arXiv:2601.07182v2 Announce Type: replace-cross \nAbstract: Policy optimization for large language models often suffers from sparse reward signals in multi-step reasoning tasks. Critic-free methods like GRPO assign a single normalized outcome reward to all tokens, providing limited guidance for intermediate reasoning . While Process Reward Models (PRMs) offer dense feedback, they risk premature collapse when used alone, as early low-reward tokens can drive policies toward truncated outputs. We in",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "Controlled Self-Evolution for Algorithmic Code Optimization",
      "link": "https://arxiv.org/abs/2601.07348",
      "summary": "arXiv:2601.07348v2 Announce Type: replace-cross \nAbstract: Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization acro",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    },
    {
      "title": "ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents",
      "link": "https://arxiv.org/abs/2601.07582",
      "summary": "arXiv:2601.07582v2 Announce Type: replace-cross \nAbstract: Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic",
      "published": "2026-01-14T00:00:00-05:00",
      "source": "arXiv CS.AI",
      "category": "deep_dive"
    }
  ]
}